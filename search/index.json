[{"content":"Before we begin, I should note that certain things simply seem impossible. You can not reason whether logic makes sense using logic. So I will not even try. We will see shortly that I find some other things to be impossible. Being trained in mathematics, I do not find that too unusual. While I think that my belief system turned out to be remarkable consistent and did not really encounter any problems in the last few years, I would be stupid to think I have discovered an absolute truth. But since the contrary is grammatically unwieldy, I will present my thoughts as such.\nWhat is?  I think, therefore I am - Descartes\n We can be sure that something exists which does the thinking. You might now argue that abstract things like language and mathematics exist. Since a version of them can be part of your consciousness, which exists. But beyond that nothing concrete needs to exist, as thought experiments like Brain in a vat or Boltzmann Brains prove (as they are not falsifiable you can not prove you are not one of those, so therefore you can not prove that anything concrete must exist).\nWe have thus proven that this question is unsolvable beyond yourself and abstract concepts which exist within your thoughts.\nWhy? 1. Analogy/Intuition building A lot of triple-A games started to include minigames. This could be a card or board game in a tavern for example. Why is that interesting to us? Well consider playing a chess minigame. When you beat a piece – why do you do it?\nThe naïve answer is: “To win the game”. But then someone might ask: But why do you want to win the game? At which point you could go one level up and argue that, as the player character in the tavern, you want to win the bet placed on the game. Or improve your skills such that you can win such a bet in the future. A follow up might be: “Fair enough, but why do you want to earn money?”. You might of course argue that you can use it in order to buy a certain item, which will help you in your campaign. But then you could still ask: “Why do you want to beat the campaign of this game?”. You might go another level up and argue, that you want to beat this campaign in order to talk with your friends about it in real life.\nContinuing to ask “why?” long enough, will eventually lead you to a point where you would have to answer the meaning of life/the purpose of all your actions in your life. At which point some people go one level up and say: “To please my god and get into heaven”. But if we take a step back, we should start to realize: Going one level up is not really solving the problem, it is really just avoiding it.\n2. Abstract Reasoning Any answer to a “why?” question, could again be questioned. Such a chain of reasoning is either\n an infinite chain goes in circles or ends at some point  In order to build some intuition for this: Consider someone \u0026ldquo;walks\u0026rdquo; in order \u0026ldquo;to walk 1km\u0026rdquo;. We have an action with a purpose. We could now easily expand this chain by supporting the action of “walking” with the reason: “to walk 0.5km” and support the action of “walking 0.5km” with the goal of “walking 0.75km”, etc. And immediately we get an infinite chain of reasoning. And since neither the infinite chain of reasoning nor the circular reasoning is really satisfying, you might want to ask for a meta-reason for the entire chain/circle. In our example this could be \u0026ldquo;to walk 1km\u0026rdquo;.\nBut then we run into the same problem with chains of meta-reasons. In the end, we will not get to a truly satisfying answer. Now the naïve answer: “To win the game” suddenly sounds much better. If we already know we can get nowhere with our questions, maybe we should not start asking them to begin with.\nBut if there is no reason to life,\nWhat do? The absence of goals allows us to choose our own. And if we are allowed to do so, we might as well choose them according to our preferences. This will be slightly different for everyone. You have a ton of Lego bricks. Do something cool with it!\nWhat is (second time)? As already argued, we cannot definitively answer this question. But since we now have to choose what we want to do as we reflected on our preferences, it might be helpful to have a model of the world around us so that we can predict the effects of our actions. Since that lets us evaluate them according to our preferences. Note that the evaluation of different actions changes with our model of the world, since it changes the predicted effect of our actions, which influences their evaluation according to our preferences.\n With very light assumptions on the preference relation (cf. Von Neumann-Morgenstern Utility Theorem) a utility function can be constructed. Once this utility function is obtained it is easy to see that we are in the setting of Reinforcement Learning (i.e. find the best policy/behaviour, which maximizes this utility function)\n No matter the preferences, it is beneficial if the model of the world has a lot of predictive power. Since that will result in valuations of actions closer to the “true” valuation, which would require perfect knowledge about how the world works. So how can we obtain a model with high predictive power?\nThis question seems similar to “What is?” on the surface. If we know what is, we can use this to predict what will be. The difference is that we can discard thought experiments like the Boltzmann Brain as not useful for predicting future events. Sure, it might be the case that you are such a Boltzmann Brain, but in that case, you will cease to exist in a few moments anyway and it does not matter what you do. And whether or not you are a brain in a vat in a simulated reality or “real” does not matter either, since we are not trying to definitively answer what truly is, but rather how our actions will influence what will be, and whether we like it. And then it does not matter whether the result is simulated or not.\nFor simplicity (and we will soon find out how important simplicity is) it might be useful to assume, that your senses do tell you something about the real world. Now that we justified why we can rely on our senses again; we have essentially justified the Scientific Method (hypothesize, predict, test/observe, repeat). Prediction from existing hypothesis is straightforward, so is testing these predictions.\n Further testing by generating predictions which can be tested vs using a well-tested hypothesis (theory) for predictions which interest you (for choosing actions according to your preferences) is known and studied as the exploration vs. exploitation trade-off in Reinforcement Learning\n What is not straightforward is generating hypotheses from observations. “What are good hypotheses?” or “what can we learn?” are the questions which Statistical Learning is concerned with. Highlights include the No Free Lunch Theorem, which motivate the intuitive preference of scientists for simple/elegant hypothesis.\n Remember that Mathematics exists so statistical learning\u0026rsquo;s theory can be relied on.\n While I recommend reading up on the “no free lunch theorem”, here is an intuitive explanation for the less mathematically inclined: If you do not assume, that physical laws are independent of space and time, they become exceedingly difficult to test. How can you confirm that some hypothesis is true, if the behaviour can change over time? It is quite hard to disprove a hypothesis which is allowed to change over time. Since that just means that it changed in such a way, that the results you got make sense again.\nThis problem is known as Overfitting and can intuitively understood with pictures like Figure 1 \u0026amp; 2.\n           Figure 1: by Chabacano - Own work, CC BY-SA 4.0, Link Figure 2: By Ghiles - Own work, CC BY-SA 4.0, Link    This simplicity requirement (which makes hypotheses robust), is the main problem with conspiracy theories. Sure they might explain the same observations, but they require a lot more “twists and turns” and are hard to test, since an observation which does not fit is simply incorporated with more twists and turns. This lack of falsifiability is the same reason, why God is a severe case of overfitting.\nThe number of twists and turns required to justify an omnipotent, benevolent god in a world with horrible disease is nauseating. And since it does not offer any measurable predictive power, the simpler hypothesis should be preferred.\nShould Where do morals come from in such a nihilistic worldview? Well for once most people prefer it, if a certain set of rules known as morals is adhered to. And since we do not justify preferences and simply take them as our reasonless foundation, there is not really anything we need to add to that.\nBut understanding where they come from might help us build a better model of the world, which is desirable as already justified. Adding together the ingredients from Game Theory (evolutionary stable equilibriums and the Folk Theorem) and our scientific evidence that we are in fact a product of evolution, it is immediately apparent that an unspoken contract of not killing each other, etc. is in fact an Evolutionary Stable Nash Equilibrium in a repeated game. So the hypothesis that morals are in fact a Folk Theorem-esque Equilibria (which are enforced by the players) requires no additional assumptions and is as such extremely simple.\nIt is also a justification why people, which do not have these equilibria baked into their preferences/feelings (psychopaths), would still benefit from adhering to these Morals. Since Equilibriums from Game Theory are also optimal for the individuum.\nA word of caution While evolution is an optimization algorithm, any intermediate step is generally not optimal. And even in the limit, the result might only be a local optimum. It is often remarkably close to optimal - which is why the entire field of Bionics exists. But there is no guarantee that this is the case.\nSimilarly, assuming our intuitive Morals/Empathy have to be optimal (i.e. Evolutionary Stable Equilibriums) would likely be wrong. But at the same time, it is probably closer to optimal than we think. And Game Theory is only starting to understand the complex settings required to generate such behaviour. So it is likely a good rule of thumb to assume that our intuitive morals are probably rational in some way.\nTrolley Problem Let us consider the trolley problem for example, which is often used to test the edges of a Moral System. In order to avoid overcomplicated sentences, and since Folk-Theorem-esque Equilibriums are really (unwritten) social contracts. I will refer to this moral system as a social contract with the understanding that there need not be a written contract.\nA lot of attention is brought to the detail, that people are reluctant to switch the lever, and are especially reluctant to throw someone over the bridge railing in order to stop the trolley. This is no surprise once we realize that actively causing a death is a greater breach of the social contract, than not preventing a death. This is due to the reason that the contract enables people to feel safe around other people but does not make any guarantee about natural causes. You could never feel save around other people if they might, at any time, throw you under the bus for the greater good. The stress level of everyone would go through the roof. At the same time everyone can and should be more attentive when they move into dangerous places like train tracks. If you would ask people the question whether they prefer to live in a world, where they can feel safe around other people but are a bit more likely to get killed if they put themselves into dangerous places, compared to the other way around, most would pick the first option. Which is why this is the social contract which is enforced.\nThat said some edge cases do not really have to be decided if they virtually never happen. Since, if the probability of them happening is really low, they will have a negligible impact on the expected utility no matter the behaviour/actions in that situation.\nWho is covered? A lot of moral systems are problematic due to the fact, that they make a distinction between humans, animals and other things. But where are the borders? In the evolutionary progression from other apes where does a human start to become a human and attain coverage of the other set of morals? If the set of morals is simply a nash equilibrium/social contract, then the question whether someone is covered by it is simply a question whether someone is intelligent enough to accept to the terms and conditions of this contract. In other words: Animals are not protected, because they cannot provide us the same guarantees in return. They are not part of the social contract and thus also cannot break it, which is why they are only tried in courts by nutcases.\nCorollary: Artificial Intelligence should get these rights as soon as it can agree to this social contract.\nMisc Subconsciousness I find the notion of a consciousness vs. subconsciousness (Libet Experiment), as if there were two people stuck in a brain and one would be you yourself and the other “someone else” which you battle for control of your body over, very strange. The “consciousness” is just the thoughts we “observe” but not in some way separate from the unconsciousness.\nI guess you can compare it to the log entries an algorithm provides for bug fixing. Some parts can also be run in “Debug mode” pushing it into consciousness, i.e. providing more diagnostic information, e.g. breathing. Debug mode is usually computationally expensive. And analyzing the logs is like doing the computation twice, so especially expensive. Therefore, doing something on autopilot is more efficient. But that does not mean that you somehow gave up control.\nEmotions vs Rationality Since we do not require our preferences to be justified by some reason, our preferences and thus overarching goals will be greatly influenced by our emotions. But in order to avoid stumbling over your own feet, it is useful to evaluate actions rationality, or consider rationally whether they will interfere with your other preferences down the road. In that sense rationality is a tool for modelling the world in order to achieve more desirable outcomes.\nFree Will I find the question whether we have free will strange. What do you even mean by free? There is no “other” entity in yourself which could enslave you. So in that sense, of course you are free!\nCreativity If you ask whether your thought process is deterministic on the other hand, completely determined by all inputs and repeatable, that is not really a question whether you are free. That is the question whether you can be truly creative and produce something new, or whether your actions are simply a function of all outside influences.\nThe answer to that is that even classical computer programs can be creative. So you certainly can be. How can classical computers be creative? Well, have a look at procedurally generated terrain. It works by combining randomness (sometimes given from outside as a seed), with some trimming algorithm for the output to make sense (look like a landscape).\nAnd if you try to observe yourself when you are creative, you will likely notice, that you do something similar. You start with something random and try to make something relatively sensible out of it. For example, finding a proof for a mathematical statement usually begins by randomly cycling through statements you have already proven, and consider for every instance, whether it might be applicable/useful (trimming).\nTL;DR Creativity = Randomness + Trimming\n","date":"2020-10-03","permalink":"https://felixbenning.github.io/blog/two-cents/concise_philosopy/","tags":["two-cents","philosophy"],"title":"Concise Philosophy"},{"content":"\u0026ldquo;It is only about pointers\u0026rdquo; Proponents of counting from 1 often think that this is about pointers and claim that it only makes sense for computer scientist as accessing an element from an array on hardware translates to addition to the pointer which means that the first element is at 0. They then like to argue that an index from 1 would make more sense in maths and \u0026ldquo;for counting\u0026rdquo;.\nI will try to explain why this is not the case.\nUse cases For that we first have to consider how indices are used and which parts might result in mistakes. And the following observation is quite important for that\n People rarely if ever want to have a particular element from a list. Almost all algorithms either iterate through through the entire list, access slices of the list or search for a particular element.\n So let us consider these use cases.\n  If you want to search for an element you never see the index anyway. You might say something like\nidx = my_list.index(my_element) # use idx in code  In that case you do not care whether the index starts from 0 or 1 as you never see the index anyway.\n  If you want to iterate through the list, you should not have to be concerned with indices either as modern languages all the in operator which yields all the elements of an iterable one by one.\nfor element in my_list: pass # do something with element    Slicing As you might guess from the header I consider slicing to be the only case where you actually have to think about indices. So let us think of some use cases.\n access the first n elements of a list access the last n elements of a list create n sized chunks (and a residual) get the column and row of a n x m matrix encoded as a vector of length nm  1. Accessing the first n elements So how could we get the first n elements in a 1 based vector? Well we would like\nl[1:n]  or\nl[:n]  and we can define it like this. But this also means that\nl[a:b] = [l[a], ...,l[b]]  and thus\nlen(l[a:b]) == b - a +1  and we will see that this becomes a sore thumb in our third task.\nSo what is the alternative? Half open intervals! Python\u0026rsquo;s 0 based indexing defines slices like this\nl[a:b] = [l[a],...,l[b-1]]  thus we get\n( len(l[a:b]) == b-a ) and ( len(l[:n]) == n )  2. Accessing the last n elements So how can we access the last n elements? Well let us first consider how to access the last element. If we use 1 based indexing with closed intervals it would be\nl[len(l)]  so you might get the last n elements with\nl[len(l)-n:]  Did you spot the bug? Remember len(l[a:b]) == b-a +1! So we actually have to write\nl[len(l)+1-n:]  So how does 0-based indexing do? Not only can you write\nl[len(l)-n:]  in 0 based indexing, you can be even more brief by realizing that\nif n \u0026lt; len(l): len(l) - n == (-n) % len(l)  in words: we can use modulo calculations to wrap around negative numbers. We could even allow arbitrary numbers to never be out of range with\nl[n % len(l)]  But out of bounds errors are sometimes quite helpful. So python only allows this for negative numbers larger than -len(l).\nIn particular you can access the last element with l[-1] and the last n elements with\nl[-n:]  Now you could do something similar in 1 based indexing, just that you do not have the beautiful modulo based (wrapping around) explanation as you skip zero. And you would end up with\nl[-len(l):]  resulting in an out of bounds error, while this is perfectly valid in python.\n3. create n sized chunks (and a residual) this is probably the most prevalent operations (e.g. converting vectors into matrices, splitting an array up into chunks for parallel processing, etc.)\nSo how does a 0 based algorithm look?\nslices = [ l[a:a+n] for a in range(len(l)/n) ] residual = l[-(n % len(l)):]  generates a list of n sized slices of l and the residual. So how would the same list comprehension look in 1 based indexing?\nslices = [ l[a:a+n-1] for a in range(len(l)/n) ] residual = l[ len(l) - (n % len(l)) +1:]  not only do you now have off-by one cases. In one case you have to subtract while you have to add if you count from the end. You are bound to mess that up on your first try if you do not carefully think about it.\n4. get the column and row of a n x m matrix encoded as a vector of length nm this is not even a battle, lets say we are row-major\n0 based:\ncolumn = idx / m row = idx % m  1 based:\ncolumn = (idx - 1) / m +1 row = (idx - 1) % m +1  let us take a victory lap and convert a (column, row) tuple back into an index\n0 based:\nidx = column * m + row  1 based:\nidx = (column -1) * m + row  Additional benefits of 0 based indexing It is often the case that you have some sort of \u0026ldquo;special\u0026rdquo; column. E.g. the \u0026ldquo;bias\u0026rdquo; or \u0026ldquo;intercept\u0026rdquo; in machine learning / statistics. In 0 based indexing, the 0th index naturally becomes this special column, and the n-th real attribute naturally maps to the index n.\nExceptions There are probably a few exceptions to the rule \u0026ldquo;you will never want to access a particular index\u0026rdquo;. While you will almost always iterate through the entire thing, I can think of at least one example where you might want to access a specific index. But it is also the only example I can think of. And since you only have to access a single index, the mental overhead for conversion is not as critical as when you have to deal with slices of (multidimensional) matrices.\nThis example I can think of is quantiles. If you want to access the median for example, you would first sort the list, and then obtain the index in the center. If \u0026ldquo;the center\u0026rdquo; exists. More generally, if you want to have the q-quantile. You would want to have the floor(len(l)/q)-th and ceil(len(l)/q)-th element and linearly combine them to obtain an approximation of the q-quantile.\nand if you use 0 based indexing you will have to shift the index down by one. Annoying but not quite as bad as the erratic plus/minus ones you have to deal with in 1 based indexing.\nSummary When accessing a particular index, 1 based indexing might make sense. But not only is that a relatively simple operations where you can deal with the additional mental overhead of an index shift. It is also a relatively rare operation.\nWhen it comes to slices, 0 based indexing with half open intervals is significantly easier to deal with than 1 based indexing with closed intervals. Arguably half open intervals are more important than 0 based indexing. Now you could of course do half open slices with 1 based indexing, but then you either have to accept that the first n elements are\nl[:n+1]  or you could have intervals which are open on the left side. In other words:\nl[a:b] = [l[a+1],...,l[b]]  note that this is equivalent to switching to 0 based indexing for slicing (with half open intervals on the right).\nDijkstra argues that it is really unintuitive to have a slice start with a lower number than the first index\nl[:n] = l[0:n] = [l[1],...,l[n]]  but I don\u0026rsquo;t think it is that much worse than half open intervals on the other side. It is definitely an improvement over closed intervals.\nBut what is a direct result of 0 based indexing, is that modulo calculus becomes significantly easier (see fourth example) and the residual in the third example. And I would say that the situations where you need to use modulo calculus on indices are not only more frequent than the situations where you need to access a particular index, but they are also more mentally taxing which means that you have less mental capacity to deal with index shenanigans.\nAnd from a practical perspective: writing programs as a student in R resulted in numerous off-by-one errors. Now I am mostly writing Python, and I can not recall the last time I had off-by-one issues.\n","date":"2020-10-03","permalink":"https://felixbenning.github.io/blog/programming/0_vs_1_based_indexing/","tags":["programming","maths"],"title":"Zero vs One-based Indexing"}]