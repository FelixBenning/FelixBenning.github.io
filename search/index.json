[{"content":"Cynical people like to call me naive, whenever I suggest how good or neutral intentions could have lead to a situation where they suspect malice. But naivety implies there would be no thought behind assuming best intentions, just lack of experience. And this is not the case.\nReason 1: I feel better Would you rather live in a world where most people mean well, or in a world where this is not the case? The same cynical people would laugh at this and claim: you can\u0026rsquo;t just live in a fantasy world!\nBut here is the thing:\nReason 2: It Is Actually True How many people do you know well enough, to actually gauge their true intentions? Of those, how many have good intentions? I would guess the majority. That is unfair, I carefully select my friends. The majority of people is still bad!\nBut how do you know? Actually know? In fact, you don\u0026rsquo;t. Nobody does. We are all extrapolating. And I simply believe you will get a more accurate model, if you extrapolate from a (possibly biased) sample of people you actually know to the general population, than just believing in something. And most people (including me) should have plenty of margin left over to add some adjustment for the bias and still end up with a majority of good natured people.\nThat being said, I do not add this bias. In fact I just assume good intentions of anyone. Why? Because it is easier. A simple model is good. And\u0026hellip;\nReason 3: It Is a Self-Fulfilling Prophecy If you assume malice, you tend to be combative, and if you are combative, people tend to respond in kind, which then confirm your initial assumptions. So this assumption is going to destroy your relationship with good natured people. Few people will make the effort to combat your assumptions about them to earn your respect.\nIf you instead start out with a high opinion of people, you are going to be nicer to them, which is going to be reciprocated. And they will also have something to lose: Your respect.\nAlthough that is the nuclear option. There is nothing more exhausting than people who try to interpret what you say in the worst way possible. If you assume the best on the other hand, two normal people can have fearless discussions, because a small misstep is not going to result in an explosion mortally wounding your relationship.\nReason 4: Dealing With Truly Bad Actors Assuming malice is also not helpful with truly bad actors. For example: Assume you are in a public discussion with someone who ends up using some sort of dog whistle. If you assume they are well-intentioned, you assume they did this by accident and would like to know about it, to avoid this mistake in the future. So you tell them nicely how this is a common dog-whistle and that they surely did not mean it that way, right? Right?\nThis way to react has multiple benefits:\n If they truly meant well, you are not offending them by assuming otherwise If they did not mean well, then you made the dog-whistle useless by forcing them to clarify in the end. The entire point of a dog-whistle is to cater to two audiences. You force them to choose one. You do not appear to be that crazy lunatic, which exploded over nothing to those people watching, which do not know that dog-whistle. You collect more data to accurately gauge their intentions  Of course you could be a cynic and just remember the mantra\n assume it was a mistake explain what is the problem ask to clarify  But your face and tone is going to betray you, if you do not truly believe it was a mistake. So you are not going to get the same effect.\nReason 5: It Is Making It Easier to Be Kind It is much easier to be nice to good people, right? So assuming people are good, makes it easier to be nice. And I want to view myself as nice.\nSummary A positive image of people is not naive. It is pragmatic. And I just do not want to be disappointed is a really bad reason to make all your future friends cross the razor wire of your distrust.\n","date":"2022-12-09","permalink":"https://www.unassuming.page/blog/two-cents/pragmatic-positive-image-of-people/","tags":["maths","two-cents","philosophy"],"title":"Pragmatic Positive Image of People"},{"content":"I am currently trying make our exercise sheets HTML based to allow for things like drop down solutions, which start in a collapsed state. I ended up asking myself whether it might be possible yet to verify proofs submitted by students automatically. So I looked for Proof Assistants and ended up with lean. In particular I tried out the Natural Numbers Game and started reading Theorem Proving in Lean for a more comprehensive introduction.\nLandmark based Maths vs Steps in Proof Assistants The first contrast I noticed was the following. When you write down Maths for another human, you tend to write something like:\nWe have\nEquation 1  which implies\nEquation 2  using induction we get\nEquation 3  In other words, you write down \u0026ldquo;Landmark\u0026rdquo; Equations and assume that the person you are talking to will be able to do the steps in-between. Sometimes you add some directional hints between those landmarks. E.g. \u0026ldquo;using induction\u0026rdquo;, but you do not actually write out precise instructions like you do in Lean.\nGiving directions in lean feels like saying:\n1. Go 10 steps South-East 2. Turn 30 degrees left and go 40 steps 3. Move your foot 30cm forward and then 10cm down 4. Repeat step 3 with alternating feet 5 times 5. Turn 50 degrees right and go 100 steps  While you would usually just say:\nturn South-East, you should see a Watertower there go there. From there continue on to...  Depending on how familiar some person is to the city you would make your description more or less precise.\nWhy the Difference? Step based instructions make perfect sense if you are trying to give directions to a robot. You circumvent the entire vision/identification problem, and you do not have to worry whether or not the culture shifts and what was once a prominent landmark is now hard to recognize, making your directions harder to read in the future.\nBut, they are absolutely garbage for a human. Because landmark based instructions provide you with information about the state you are in. And it is easy to check whether you are really at a water tower or whether you really got to the next equation. With step based instructions it is often difficult to know whether or not you followed the steps correctly so far.\nIn other words: you never know if you are in the correct state if you are not perfectly sure that you made the right steps beforehand. And I noticed this writing down proofs myself: I greatly depend on lean telling me the current state interactively when hovering over some step.\nIn this sense lean feels like the assembly of theorem proving, possibly C. It is shaped by the requirements of a computer and you need your IDE to help you navigate the code as a human.\nSolving the vision problem Is it possible to write landmark based directions and compile them into steps? Maybe. But also maybe not. There is probably a reason Lean was not designed that way. This might be difficult to do with explicit instructions.\nBut just like you would not attempt to solve a vision/classification problem with classic code, maybe this is not a task for a compiler but machine learning.\nNow if you are aware of OpenAi Codex (GitHub Copilot), you might be guessing where this is going. GitHub Copilot attempts to autocomplete your code based on comments, function stubs or list stubs.\nNow image GitHub copilot could fill in the instructions between the following comments\n-- Move around the corner to your south-east Go 10 steps South-East Turn 30 degrees left and go 40 steps -- walk down the set of stairs Move your foot 30cm forward and then 10cm down Repeat step 3 with alternating feet 5 times -- walk towards the water tower on your right Turn 50 degrees right and go 100 steps  But for this to work, you need to be able to train your Copilot on existing code with comments. How could you obtain such a dataset? Well\u0026hellip;\nTypesetting Interactive Maths Let us forget the issue we had for a second and consider a different problem. If you want to create an interactive proof, you can not really use (La)TeX. Not only because it is a legacy programming language few people dare to touch, but also because it is on the other side of the machine-interpretable vs human-interpretable side.\nFor example, MathML uses a unicode for invisible multiplication (U+2062) and one for function applications (U+2061) to discern between the two interpretations of\nh(x+y)  One being that h is a function, the second being that h is a constant multiplied with the sum of x and y. TeX simply does not have that. Now MathML has its own problems. Browser support is abysmal. It is basically only fully supported by Firefox. This means that conversion tools like latexml suggest including a fallback script, which includes MathJax for any browser which is not Gecko based. Of course MathJax is MathML based,\n MathJax uses MathML as the basis for its internal format for mathematical expressions, so MathML support is built into MathJax at a fundamental level. - https://docs.mathjax.org/en/latest/output/mathml.html\n so there isn\u0026rsquo;t really a way around MathML either, if you want to typeset mathematics for the web. But writing MathML directly is no fun either since it is incredibly verbose. So if you are not converting existing .tex files using a tool like latexml. You are probably better of, with a combination of html or markdown and MathJax or KaTeX. Even though that entails marrying the different escape mechanisms of html or markdown with the TeX escapes (multiple backslashes ensue), and working around the fact that MathJax and KaTeX are far from feature complete TeX compilers.\nOn the whole: not a fun experience, 1/10, would recommend for the lack of better options.\nTypesetting with Lean? Imagine you could render your Lean proof. One thing would be certain: The computer understands what is going on. Therefore if you do not understand an equation, you could easily use the rewrite rules in your proof to do stuff like animate how the next equation comes to be. But you could certainly add a bunch more steps in-between. In other words: a proof typeset with Lean could be fully interactive and personalized for the reader. How much you show a person might depend on what they read before and how they collapsed or expanded steps before. Maths would become arbitrarily accessible!\n","date":"2022-04-04","permalink":"https://www.unassuming.page/blog/mathematics/proof_asssistants_for_typesetting_maths/","tags":["two-cents","maths"],"title":"Proof Assistants for Typesetting Maths"},{"content":"If you use a test with 95% sensitivity and 95% specificity, and it is positive then you are surly more likely sick than not, right? Well, ... it depends. On the prior probability to be sick (or prevalence) to be precise. And humans are really bad assessing the meaning of a test result. Here is a bayes calculator to make this easer:\nPrevalence Sensitivity Specificity Test positive? Likelihood to be infected:   Disclaimers  In the case of Covid-19 the incidence is often reported instead of the prevalence. While similar, that is a different measure. The prior (prevalence) is also modified if there is a specific reason for doing the test. I.e. the prevalence of Covid-19 in the total population is lower than the prevalence in the population of people with a cough.  Also keep in mind that some of the specificity and sensitivity labels provided by the tests themselves turned out to be false in independent testing. It is therefore advisable to use independent sensitivity estimates like the ones measured by the Paul-Ehrlich Institute. Lastly the sensitivity varies depending on the virus load.  function calculatePosterior(prior, sensitivity, specificity, test_positive) { const p_test_given_pos = test_positive ? sensitivity : 1-sensitivity if (prior === 0 || p_test_given_pos === 0){ return 0 } const p_test_given_neg = test_positive ? 1-specificity : specificity return 1/(1+ p_test_given_neg*(1-prior)/(p_test_given_pos*prior)) } function handlePosteriorRecalculation() { bayesForm = document.getElementById(\"bayes-calculator\"); const prior = bayesForm.prevalence.valueAsNumber/100000.0; const sensitivity = bayesForm.sensitivity.valueAsNumber/100.0; const specificity = bayesForm.specificity.valueAsNumber/100.0; bayesForm.posterior.value = new Intl.NumberFormat( \"en-In\", {\"maximumSignificantDigits\": 4, \"style\": \"percent\"} ).format(calculatePosterior( prior, sensitivity, specificity, bayesForm.test_positive.checked )); } function handleInputCheckValidity() { bayesForm = document.getElementById(\"bayes-calculator\"); if (bayesForm.checkValidity()) { handlePosteriorRecalculation(); } else { bayesForm.posterior.value = \"Missing Input\" } } bayesForm = document.getElementById(\"bayes-calculator\"); bayesForm.addEventListener(\"input\", handleInputCheckValidity); handleInputCheckValidity(); // first check function add_wasModified() { this.classList.add(\"modified\"); } for (const input of document.getElementsByTagName(\"input\")) { input.addEventListener(\"input\", add_wasModified); } ","date":"2022-01-22","permalink":"https://www.unassuming.page/blog/tools/bayes-helper/","tags":["maths","tools","health"],"title":"Bayes Helper"},{"content":"If there is one thing this pandemic has taught us, then it is that few people truly understand exponential growth. This post is an attempt to explore this magical function with minimal prerequisites.\nHow do we know something will behave exponentially? When you hear exponential growth, you probably picture a curve that starts increasing slowly and increases faster and faster. And that is how many people use the term: \u0026ldquo;Something that increases faster and faster\u0026rdquo;, even though the relation might not be exponential at all. And if that is how you think about exponential growth, it is quite natural to doubt that a disease should spread exponentially. I mean why should it spread faster and faster? This seems like it requires an explanation.\nTo actually understand why, it is helpful to forget this preconceived notion of exponential growth. Instead we are going to build it from the ground up. In other words, we are going to define exponential growth in a way which makes it obvious why disease should spread this way, and then we will show that this type of growth becomes faster and faster. Not the other way around.\nSo how can we model an infectious disease? Let us start with a single person getting infected. This person is going to meet a random number of other people and infect them with a certain probability. Let us say that on average, an infected person infects $0.7$ other people per day. Similarly the person might become healthy again, perhaps half of the infected people will become healthy every day.\nSo the change of infected people from one day to another is\n $$ \\begin{aligned} \\Delta \\text{infected} \u0026= \\text{newly\\_infected} - \\text{recovered}\\\\ \u0026= 0.7\\cdot\\text{infected} - 0.5\\cdot\\text{infected}\\\\ \u0026= 0.2\\cdot\\text{infected}. \\end{aligned} $$  Now you might find my particular selection of infection rates and recovery rates unrealistic. That is fine. Select other rates. The only thing I want you to realize is, is that both the number of newly infected people as well as the number of recovered people is proportional to the currently infected number of people. In other words: Our rate of change is just a constant multiplied with the current number of infected people\n$$ \\Delta \\text{infected} = c\\cdot\\text{infected}. $$\nThis property\n the rate of change is proportional to the current value\n is how exponential growth should actually be defined. Now we just need to get back to the faster and faster growth bit. So consider the infections $I_d$ at day $d$\n $$ I_d = I_{d-1} + \\underbrace{(\\Delta I)_d}_{=cI_{d-1}} = (1+c) I_{d-1}. $$  Iterating on this idea (\u0026ldquo;induction\u0026rdquo;) yields\n$$ I_d = (1+c) I_{d-1} = (1+c)^2 I_{d-2}=\\dots=(1+c)^d I_0. $$\nSo now we have a function to predict the number of infected people on day $d$ given a set number of people infected on day zero $I_0$\n$$ I(d) = (1+c)^d I_0. $$\nFaster and Faster Growth For $c=0.2,$ as we have used in the motivation above, and one infected person on day zero $I_0=1,$ we get\n   Day Infected People Rate of Change     0 1 -   1 1.2 +0.2   2 1.44 +0.22   3 1.73 +0.29   \u0026hellip; \u0026hellip; \u0026hellip;   30 237.38 +39.56   40 1 469.77 +244.96   50 9 100.44 +1516.74   60 56 347.51 +9 391.25   \u0026hellip; \u0026hellip; \u0026hellip;   90 13.37 mio +2.23 mio   100 82.8 mio +13.80 mio    After the first month only $236$ people are infected, which is less than a school. One month later it is a small town. One more month and more than $15\\%$ of Germany is infected, 10 days later the entirety of Germany. And it would continue growing like that! Wait a minute\u0026hellip; How can it continue to grow when the entire population is infected? Well we made a small mistake. You cannot infect an already infected person. So we need to subtract the number of already infected people from the number of people a person would have infected if there were no other infected people around.\nBut at the beginning of a pandemic, there are not that many infected people around, so the likelihood of \u0026ldquo;infecting an already infected person\u0026rdquo; is very low because you do not meet many infected people. In other words: if the number of infected people is small, then this correction we need to make is negligible. For this reason, exponential growth is a reasonable approximation to infectious behavior until the number of infected people becomes large enough such that it is likely that you pseudo infect some of them as a infected person. Only then does this problem actually start to have an effect.\nTakeaways for Pandemics An incidence rate of 2000 (per 100 000) might be high when it comes to hospitalizations and the strain on the healthcare system, but as a share of the population it is still \u0026ldquo;only\u0026rdquo; $2\\%.$ Therefore the likelihood that a sick person meets another infected is only $0.02$ which is still quite small. Therefore exponential growth is still a good approximation. For smaller incidence rates this is even more so. So exponential growth is a good approximation during the entire pandemic. The most important thing here is the growth factor $c$. The equivalent quantity, the reproductive value $R=(1+c)$ is what was (and is) widely published during the pandemic, or to be more precise $R_0=(1+c)$ (which does not take already infected people into account).\nIn our example we had a relatively mild reproductive value of $1.2$ and yet the disease spread like wildfire. So when an $R$ value of $3$ was estimated at the beginning of the pandemic, anyone who understood how exponential functions work shook their heads when politicians argued \u0026ldquo;but it is just 3 people\u0026rdquo;. And if you were not before, I hope you are one of those next time.\n","date":"2022-01-21","permalink":"https://www.unassuming.page/blog/mathematics/why-disease-spreads-exponentially/","tags":["education","maths","politics"],"title":"Why Disease Spreads Exponentially"},{"content":"Probability theory is best understood through the lense of \u0026ldquo;the expected value\u0026rdquo;. We are fundamentally trying to understand what we can expect so the expected value is a great place to start\nExpected Value Starting Small Let\u0026rsquo;s say you play a game of dice where you win 2€ if you roll a 6 and lose 1€ if you roll any other number. Then we want to calculate what you should expect to receive \u0026ldquo;on average\u0026rdquo;. Now most people find the practice of multiplying the payoff by its probability and summing over them relatively straightforward. In this case you get\n $$\\text{Expected Payoff} = \\frac{1}{6} 2€ + \\frac{5}{6}(-1€) = -0.5€$$   Now let us try to formalize this and think about what is happening here. We have a set of possible outcomes $\\Omega=\\{1,2,3,4,5,6\\}$ where each outcome is equally likely. And we have a mapping $Y:\\Omega \\to \\mathbb{R}$ which denotes the payoff. I.e.  $$ Y(\\omega) = \\begin{cases} 2 \u0026 \\omega = 6,\\\\ -1 \u0026 \\text{else} \\end{cases} $$  And then the expected payoff is\n $$ \\mathbb{E}[Y] = \\frac{1}{|\\Omega|}\\sum_{\\omega\\in\\Omega} Y(\\omega) = \\frac{1}{6}(2 + (-1) + ... + (-1)) = -0.5 $$  where $|\\Omega|$ is the number of elements contained in $\\Omega$.\nIntroducing Infinity Now this works fine for finite $\\Omega$, but what if the set of possible outcomes is infinite? What if every real number in $[0,1]$ was possible, equally likely, and the payoff would look like this?\n $$ Y: \\begin{cases} [0,1] \\to \\mathbb{R} \\\\ \\omega \\mapsto \\begin{cases} 2 \u0026 \\omega  \\frac{5}{6} \\\\ -1 \u0026 \\omega \\le \\frac{5}{6} \\end{cases} \\end{cases} $$  Intuitively this payoff should have the same expected payoff as the previous one. But if we simply try to do the same thing as previously\u0026hellip;\n $$ \\mathbb{E}[Y] = \\frac{1}{|\\Omega|}\\sum_{\\omega\\in\\Omega} Y(\\omega) = \\frac{1}\\infty (\\infty - \\infty)... $$  Okay so we have to be a bit more clever about this. If we have a look at a plot of your payoff $Y$,\nwe might notice that the area under the curve is exactly what we want.\n $$ -1€\\left(\\frac56-\\frac06\\right) + 2€ \\left(\\frac66 - \\frac56 \\right) = -0.5€ $$  Now why is this the same? How are our sums related to an area under a curve?\nSumming to one To understand this it might be useful to consider what the expected value of a simpler function is\n $$ \\mathbf{1}: \\begin{cases} \\Omega \\to \\mathbb{R}\\\\ \\omega \\mapsto 1 \\end{cases} $$  In our first example this was\n $$ \\frac{1}{|\\Omega|} \\sum_{\\omega\\in\\Omega} \\mathbf{1}(\\omega) = \\frac{|\\Omega|}{|\\Omega|} $$  In our second example this would be\n $$ \\int_{\\Omega} 1 d\\omega = \\int_0^1 1 d\\omega $$  Now if we recall how the integral (area under the curve) is calculated we might notice that in case of indicator functions, we are weighting the height of the indicator function with the size of the interval. And the size of the interval is its length.\nSimilarly we could move $\\frac{1}{|\\Omega|}$ into the sum and view it as the weighting of each $\\omega$. And here is where we have the crucial difference:\nIn the first case individual $\\omega$ have a weight (a probability), while individual points in an interval have no length/weight/probability. But while sets of individual points have no length, an infinite union of points with no length/probability can have positive length/probability.\nThis is why probability is closely intertwined with measure theory, where a measure is a function assigning sets (e.g. intervals) a weight (e.g. lenght, or probability).\nDoing it properly So if we restart our attempt at defining the expected value, we start with a probability space $\\Omega$ and a probability measure $P$ which assigns subsets of $\\Omega$ a probability. A real valued random variable (e.g. payoff) $Y$ is a function from $\\Omega$ to $\\mathbb{R}$. And if it only takes a finite number of values in $\\mathbb{R}$ (i.e. $Y(\\Omega)\\subseteq \\mathbb{R}$ is finite), then we can calculate the expected value by going through these values, weightening them by the probability of their preimages and summing them.\n $$ \\mathbb{E}[Y] = \\sum_{y\\in Y(\\Omega)} y P[Y^{-1}(\\{y\\})] $$  To make notation more readable we can define\n $$ \\begin{aligned} P[Y\\in A] \u0026:= P[Y^{-1}(A)] \\qquad\\text{and} \\\\ P[Y=y]\u0026:=P[Y\\in\\{y\\}] \\end{aligned} $$  In our finite example the expected value is\n $$ \\begin{aligned} \\mathbb{E}[Y] \u0026= 2 P(Y=2) + (-1) P(Y=-1)\\\\ \u0026=2 P(Y^{-1}[\\{2\\}]) +(-1)P(\\{1,2,3,4,5\\})\\\\ \u0026= 2 \\frac16 -1 \\frac56 = -0.5 \\end{aligned} $$  In our infinite example the expected value is\n $$ \\begin{aligned} \\mathbb{E}[Y] \u0026= 2P(Y=2) + (-1)P(Y=-1)\\\\ \u0026= 2P\\left(\\left(\\frac56, 1\\right]\\right) - P\\left(\\left[0, \\frac56\\right]\\right) = \\int_0^1 Y d\\omega\\\\ \u0026= 2 \\frac16 - \\frac56 = -0.5 \\end{aligned} $$  Now it turns out that you can approximate every $Y$ with infinite image $Y(\\Omega)$ with a sequence of mappings $Y_n$ with finite image. And that the limit\n $$ \\int_\\Omega Y dP := \\lim_n \\int_\\Omega Y_n dP := \\sum_{y\\in Y_n(\\Omega)} y P(Y=y) $$  is also well defined and independent of the sequence $Y_n$. Lebesgue Integral The integral we defined above is called the Lebesgue Integral. The neat thing about it is, that\n Riemann integration is a special case of it, if we integrate over the Lebesgue Measure $\\lambda$ which assigns intervals $[a,b]$ their length $\\lambda([a,b])=b-a$. $$\\int_{[a,b]} f d\\lambda = \\int_a^b f(x) dx$$ Sums and series are also a special case using sequences $(a(n), n\\in\\mathbb{N})$ and a \u0026ldquo;counting measure\u0026rdquo; $\\mu$ on $\\mathbb{N}$ which assigns a set $A$ its size $\\mu(A) = |A|$. Then  $$ \\int_{\\Omega} a d\\mu = \\sum_{n\\in\\mathbb{N}} a(n) $$\nThe implications are of course for one, that one can often treat integration and summation interchangeably. Proving statements for Lebesgue integrals is rarely harder than proving them for Riemann integrals and in the first case all results also apply to series and sums.\nIt also means we can properly deal with \u0026ldquo;mixed cases\u0026rdquo; where some individual points have positive probability and some points have zero probability on their own but sets of them have positive probability.\nMy stochastics professor likes to call integration just \u0026ldquo;infinite summation\u0026rdquo; because in some sense you are just summing over an infinite number of elements in a \u0026ldquo;proper way\u0026rdquo;.\n The lebesgue integral also makes certain real functions integrable which are not integrable with riemann integration. The function $\\mathbf{1}_{\\mathbb{Q}}$ is not riemann integrable, but poses no problem for lebesgue integration. The reason is, that riemann integration subdivides the $x$-axis and $y$-axis into intervals without consulting the function that is supposed to be integrated, while lebesgue integration only subdivides the $y$-axis and utilizes the preimage information about the function that is supposed to be integrated.\n Back to Intuition Now the end result might not resemble our intuition about \u0026ldquo;expected values\u0026rdquo; anymore. We get some of that back with theorems like the law of large numbers which proves that averages\n$$\\frac{1}{n} \\sum_{k=1}^n X_k$$\nof independently, identically distributed random variables converge (in various senses) to the theoretically defined expected value $\\mathbb{E}[X]$.\nA note on Random Variables In our examples above, only the payoff $Y$ was a random variable (a function from the probability space $\\Omega$ to $\\mathbb{R}$). But since we can compose functions by chaining them, nothing would have stopped us from defining the possible die faces as a random variable of some unknown probability space $\\Omega$. Since our payoff is just a function of the die faces, their composition would also be a function from $\\Omega$. And it is often convenient not to define $\\Omega$ and start with random variables right away, as it allows easy extensions of our models without having to redefine our probability space. Because we treat the underlying probability space as unknown anyway and only work with known windows (random variables) into it. Notice how you could not discern the die faces ${1,\u0026hellip;,5}$ from payoff $Y=-1$ alone. So random variables can also be viewed as information filters.\nLies While we would like our measures to assign every subset of $\\Omega$ a number, this is generally not possible without sacrificing its usefulness.\nIf we wanted a measure on $\\mathbb{R}$ which fulfills the following properties\n translation invariance (moving a set about does not change its size) countable summability of disjoint sets positive finite on every bounded set  we are only left with the $0$ measure (assigning every set measure 0).\n Proofsketch: Use the axiom of choice to select a representative of every equivalence class of the equivalence relation $x-y\\in \\mathbb{Q}$ on the set $[0,1]$. This set of representatives is not measurable, because translations by rational numbers modulo 1 transforms it into distinct other representation sets of the equivalence relation. And since they are disjoint and countable we can sum over them and get the measure of the entire interval $[0,1]$. But an infinite sum of equally sized sets can not be finite if they are not all $0$. Therefore the set $[0,1]$ must have measure 0 and by translation and summation all other sets in $\\mathbb{R}$\n For this reason we have to restrict ourselves to a set of \u0026ldquo;measurable sets\u0026rdquo; (a sigma Algebra) which is only a subset of the powerset $\\mathcal{P}(\\Omega)$ of $\\Omega$. This conundrum also limits the functions we can integrate with lebesgue integration to the set of \u0026ldquo;measurable functions\u0026rdquo;.\nBut all of these things are technicalities distracting from the intuition.\n","date":"2022-01-20","permalink":"https://www.unassuming.page/blog/mathematics/probability/","tags":["education","maths"],"title":"Introduction to Probability"},{"content":"Linear functions define matrix multiplication and make matrices and linear functions effectively interchangeable.\n1. Basis  $$ \\begin{aligned} \\begin{pmatrix} x_1 \\\\ \\vdots \\\\ x_d \\end{pmatrix} \u0026= x_1 \\begin{pmatrix} 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix} + \\dots + x_d \\begin{pmatrix} 0 \\\\ \\vdots \\\\ 0 \\\\ 1 \\end{pmatrix}\\\\ \u0026= x_1 \\vec{e}_1 + \\dots + x_d \\vec{e}_d \\end{aligned} $$  2. Linearity Defines Matrix-Vector Multiplication  $$ \\begin{aligned} f\\begin{pmatrix} x_1 \\\\ \\vdots \\\\ x_d \\end{pmatrix} \u0026= f(x_1 \\vec{e}_1 + \\dots + x_d \\vec{e}_d) \\\\ \u0026= x_1 f(\\vec{e}_1) + \\dots + x_d f(\\vec{e}_d) \\qquad \\text{(linearity)}\\\\ \u0026= \\begin{pmatrix} | \u0026 \u0026 |\\\\ f(\\vec{e}_1) \u0026 \\dots\u0026 f(\\vec{e}_d)\\\\ | \u0026 \u0026 | \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ \\vdots \\\\ x_d \\end{pmatrix} \\end{aligned} $$  3. Composition Defines Multiplication of Matrices The property\n $$ \\begin{aligned} g\\circ f(e_i) \u0026= \\begin{pmatrix} | \u0026 \u0026 |\\\\ g(\\vec{e}_1) \u0026 \\dots\u0026 g(\\vec{e}_d)\\\\ | \u0026 \u0026 | \\end{pmatrix} \\begin{pmatrix} | \\\\ f(\\vec{e}_i)\\\\ | \\end{pmatrix} \\end{aligned} $$  implies\n $$ \\begin{pmatrix} | \u0026 \u0026 |\\\\ g\\circ f(\\vec{e}_1) \u0026 \\dots\u0026 g\\circ f(\\vec{e}_d)\\\\ | \u0026 \u0026 | \\end{pmatrix} = \\begin{pmatrix} | \u0026 \u0026 |\\\\ g(\\vec{e}_1) \u0026 \\dots\u0026 g(\\vec{e}_d)\\\\ | \u0026 \u0026 | \\end{pmatrix} \\begin{pmatrix} | \u0026 \u0026 |\\\\ f(\\vec{e}_1) \u0026 \\dots\u0026 f(\\vec{e}_d)\\\\ | \u0026 \u0026 | \\end{pmatrix} $$\t","date":"2021-07-26","permalink":"https://www.unassuming.page/blog/mathematics/little-exposition/matrix-multiplication/","tags":["linear-algebra","maths","education"],"title":"Matrix Multiplication"},{"content":"Let\u0026rsquo;s say we want to approximate a function $f$. In an area around $a$ the value $f(a)$ is probably a decent approximation for $f(x)$.\nUsing the Fundamental Theorem of Calculus we can calculate the error\n$$ f(x) - f(a) = \\int_a^x f'(y)dy $$\n If $f'$ is bounded by $\\|f'\\|_\\infty$ then our error is smaller than $\\|f'\\|_\\infty (x-a)$. We can now improve this bound by approximating $f'$ itself in the same way:  $$ \\begin{aligned} f(x) - f(a) \u0026= \\int_a^x \\left( f'(a) + \\int_a^y f''(s)ds \\right) dy\\\\ \u0026= f'(a) (x-a) + \\int_a^x \\int_a^y f''(s)ds dy\\ \\end{aligned} $$  Which results in a more precise approximation of $f$:\n$$ f(x) \\approx f(a) + f'(a)(x-a) $$\n If $f''$ is bounded then our error is now only $\\|f''\\|_\\infty(x-a)^2$ a significant improvement over the previous error close to $a$. Iterating on this idea yields the taylor approximation. If all the derivatives are bounded by the same constant, the error converges towards zero, the function is a taylor series\n $$ \\begin{aligned} f(x) \u0026= f(a) + f'(a)(x-a) + f''(a)\\frac{(x-a)^2}{2} + \\dots\\\\ \u0026= \\sum_{k=0}^\\infty f^{(k)}(a)\\frac{(x-a)^k}{k!} \\end{aligned} $$  Application: Exponential Function If the change of something is equal to the current size (e.g. number of bacteria as it increases via cell division) then that implies $f=f'$. If we also assume $f(0)=1$ for normalization then we immediately obtain the series representation of the unique function with this property: the exponential function\n $$ \\exp(x) = \\sum_{k=0}^\\infty \\exp(0) \\frac{(x-0)^k}{k!} = \\sum_{k=0}^\\infty \\frac{x^k}{k!} $$  Taylor Approximation in Multiple Dimensions To obtain the Taylor\u0026rsquo;s Theorem for functions $f:\\mathbb{R}^d\\to\\mathbb{R}$ from multiple dimensions one can simply reduces them to the one dimensional version of the taylor theorem with the following trick. For $a,x\\in\\mathbb{R}$ we can define\n $$ g :\\begin{cases} [0,1] \\to \\mathbb{R} \\\\ s\\to f(a+s(x-a)) \\end{cases}\t$$  which means we can apply the one dimensional taylor theorem from above to $g$ to get\n$$ \\begin{aligned} f(x) \u0026= g(1) = g(0) + g'(0)(1-0) + g''(0)\\frac{(1-0)^2}{2} + \\dots\\\\ \u0026=f(a) + \\nabla f(a)^T(x-a) + \\tfrac12 (x-a)^T\\nabla^2f(a)(x-a) + \\dots \\end{aligned} $$","date":"2021-07-25","permalink":"https://www.unassuming.page/blog/mathematics/little-exposition/taylor-approximation/","tags":["analysis","maths","education"],"title":"Taylor Approximation"},{"content":"We want to find $a_1$ and $a_2$ using only $p$ and $q$\n $$ x^2 - \\underbrace{(a_1+a_2)}_{p}x + \\underbrace{a_1a_2}_{q} = (x-a_1)(x-a_2). $$  With\n $$ q= a_1a_2= (m-d)(m+d) = m^2 - d^2, $$  we immediately get the p-q formula\n $$ \\begin{aligned} a_{1/2} \u0026= m \\pm d \\\\ \u0026= m \\pm \\sqrt{m^2 - q}\\\\ \u0026= \\frac{p}{2} \\pm \\sqrt{\\left(\\frac{p}{2}\\right)^2 - q} \\end{aligned} $$   Source: 3blue1brown\n","date":"2021-07-24","permalink":"https://www.unassuming.page/blog/mathematics/little-exposition/pq-formula/","tags":["algebra","maths","education"],"title":"pq-Formula"},{"content":"While equal rights could be viewed as an issue of the past (at least in most developed countries), equal opportunity is still an open issue. In a free market wages and hiring decisions are not up to the law and thus equal rights are not enough to guarantee equal opportunity. While wages for equal work can be achieved with transparency and public pressure, it is much more difficult to quantify hiring discrimination. For this reason many people argue for a quota to actually affect these decisions with written law, so that injustices could be tried in court.\nViolent Agreement over the Premise While quotas seem contentious, both, proponents as well as opponents argue with the same premise: \u0026ldquo;hiring should be determined by merit, not demographics\u0026rdquo;. But proponents of the quota point to data showing demographics seemingly influencing hiring decisions right now, and want to correct them with a quota. While opponents argue that these decisions are due to individual preferences for certain types of jobs which might be correlated with demographics but are ultimately every individuals free choice. They might back that up with enrollment statistics correlated with demographics as well, where colleges and schools are subject to non-discrimination laws due to their public nature.\nI do not really want to go to deep into the question which side is right, since that would at the very least require a deep dive into the data and might not even be answerable with the data.\nSo I am not going to. Why do I have any business writing about this topic then? Well, I guess it is in the title.\nBlind Resume Quota While it is possible to redact personal details from a resume - making it blind, it is basically impossible to do so in person (be it interviews or probation periods). So redacting personal details alone does not solve the problem. But now you have a better base distribution to compare hiring decisions to.\nThe fundamental assumption of a blanket quota is, that the chance that someone is qualified for a job is proportional to the size of their demographic. The idea is now, to use \u0026ldquo;passing the blind resume review\u0026rdquo; as a proxy for merit and demand that the chance that someone is hired given that they passed the blind resume review is independent of their demographic affiliation.\nQuotas could be dynamically adjusted to this benchmark (with some margin for statistical error determined by a confidence interval).\nThe underlying assumption of this quota is of course, that there is no difference in the ability to write resumes which get accepted conditioned on merit. To me this seems like a much weaker assumption than a blanket \u0026ldquo;everyone has the same preferences\u0026rdquo; assumption.\nAlternatives I am not really married to the idea of blind resumes. But the idea to use a proxy for merit to detect actual discrimination would likely make quotas much less controversial.\nTo make an absurd comparison: While it would not make much sense to assert that the share of physicians in engineering jobs should be equal to their share of the population, it is much less likely that physicians will be underrepresented in engineering once one conditions on the number of accepted blind resumes.\nSuch a proxy should therefore be well suited to rule out preferences as a source. This ultimately means that people who had objections to blanket quotas might be perfectly fine with such a smart quota. At least if the proxy is decent.\n","date":"2021-05-22","permalink":"https://www.unassuming.page/blog/two-cents/smart-quota/","tags":["politics","two-cents"],"title":"Smart Quotas"},{"content":"Utility Everyone has preferences. In some sense it defines what being alive means and I tend to view preferences as axioms. They are also treated as axioms in economics. But what are preferences?\nFormally preferences are a binary relation on the set of possible world states. The greater or equal symbol \u0026ldquo;≥\u0026rdquo; is such a binary relation for example and a good intuition for what we are getting at. We then make certain assumptions about this relation:\n  First of all we assume connexity (also called \u0026ldquo;completeness\u0026rdquo;). This just means that we can compare any two world states, which means that for any two world states A and B, we either \u0026ldquo;weakly prefer A over B\u0026rdquo; (A ≿ B) or we \u0026ldquo;weakly prefer B over A\u0026rdquo; or both. If both are true (we weakly prefer A over B and weakly prefer B over A), then we say we are \u0026ldquo;indifferent between A and B\u0026rdquo; (A ~ B).\n  For this reason we also require reflexivity, i.e. we always weakly prefer A over A for any world state A.\n  The last crucial assumption is transitivity which means that we weakly prefer A over C if we weakly prefer A over B and B over C.\n  These three assumptions are the base assumptions for ordinal utility. While this relation is very similar to the \u0026ldquo;greater or equal\u0026rdquo; (≥) relation, it is not the same. The crucial difference is that preferences do not have to be antisymmetric, which means that (A ≥ B) and (B ≥ A) imply equality (A = B). Because we can have two distinct world states we are indifferent in between without them being the same world state. For the same reason preferences are not a total order.\nIf the set of all possible world states is finite (or countable to be precise), then these three assumptions about the preference relation are enough to prove the existence of a utility function. A utility function $u$ assigns every world state a numeric value (real number) and has the property that comparing the numeric values of world states is equivalent to comparing two world states, i.e.\n$$u(x)\\ge u(y) \\iff x \\succsim y$$\nIn other words: a utility function transforms an abstract preference relation on world states into a greater or equal relation on numbers. This makes it a lot easier to work with.\nNow it is important to note that the existence of a utility function does not mean that this utility function is unique. In fact adding a constant to a utility function does not change the ordering, so this results in another valid utility function. In fact any monotonous transformation of a utility function is still a utility function describing the same preference relation. This means that the specific number (the utility) which is assigned to a world state is meaningless by itself, because it is not unique. This is similar to how the number 10 is meaningless for measuring temperature without a unit (like celsius) to go with.\nWhat is not meaningless are indifference curves (sets). Indifference curves are basically contour lines of the utility function. Think of hight maps where the circle of points on the same hight around a mountain are marked with a line, or isobars in pressure maps. While the the particular number assigned to these utility levels is pretty meaningless, the shape of these indifference curves are often enough to explain how trade works.\nOf course in reality the set of world states is much more complicated than a two dimensional surface with a height. But if you imagine a world state being a vector with many different attributes, you can keep all those attributes the same except for two (what economists like to call \u0026ldquo;ceteris paribus\u0026rdquo; - \u0026ldquo;all things being equal\u0026rdquo;) and use this slice of all possible world states to create such a visualization. One might for example keep all attributes constant except for the amount of good X and Y a person possesses and get a height map like this.\nIf we assumed for a minute that those lines would be straight, you could determine the slope of this line by selecting a point on the line, going left by one unit and going up until you hit the curve again. The length you need to go to up is the amount of the good Y you need to receive to make up for the lost good X because then you end up on the curve again (which is by definition the set of points you are indifferent in between). Now if the lines are not straight, they might still appear to be straight if you zoom in enough. This zooming in is basically taking the derivative and this ratio is also called the marginal rate of substitution. Around a particular point on the curve, you are willing to trade X for Y if you get at least this ratio of Y for X and vice versa.\nAs long as you do not end up in some corner case, where someone has already traded all X for Y (or Y for X), trades will continue to happen until the going exchange rate is equal to everyone\u0026rsquo;s marginal rate of substitution. This observation is the basis for the first fundamental theorem of welfare economics, which essentially states that an (idealized) free market (with perfect information, no market power, no externalities, etc.) will result in a pareto optimal outcome. Pareto optimal means that no individual can be made better off, without also making somebody worse off.\nNote that Pareto optimality does not make any statements about fairness. It is more of a bare minimum to exclude a bunch allocations which do not even fulfill such a basic requirement everyone can agree on. Something like fairness is a much more difficult goal because it is very difficult to define and much more subjective. It would often require comparing utility functions or somehow summing them, which is not really possible since they are not unique. And if you want to make the preferences of someone more important you could simply multiply their utility function with a large number, then the result is still a utility function describing their preferences, but suddenly everything which makes them worse off results in really big utility differences.\nIn practice people usually solve this issue by evaluating everything according to their own utility function by imagining themselves in the shoes of other people and evaluating the impact of their actions according to their own preferences. This works as long as preferences are sufficiently similar. Everyone can relate to hunger, so people usually agree that it is \u0026ldquo;the right thing\u0026rdquo; to prioritize that over basically everything else for others as well. But people can not always relate to others preferences and that is usually where disagreements happen.\nCombining the utility functions of many individuals into one preference of society of sorts is not only difficult, it can in fact be shown that it is impossible. This result is known as the Condorcet Paradox or Arrow\u0026rsquo;s Impossibility Theorem, where the condorcet paradox is more of a concrete example for weird behavior happening with different known voting systems while arrows impossibility theorem proves that there cannot be any voting system which has certain properties everyone would agree a voting system should have. PBS Infinite series made two excellent videos explaining those two results.\n   Since combining individuals utility functions into one social preference function for society is actually impossible economists usually stay away from fairness arguments. This might be surprising as it might seem that pareto efficiency should naively be a given. Everyone agrees that things should happen if it makes someone better of and nobody worse off. So it seems that the real problem should be making the world fair, as pareto efficiency should be easy. But this is in fact not the case. Achieving pareto efficiency is often not a given and in some cases even impossible.\nIn the following chapters we will encounter many such situations where there is no good solution to even achieve pareto efficiency let alone fairness.\nWhy Trade is Good Economists generally like free trade - because restricted trade does usually not result in pareto optimal outcomes.\n    Alice Bob     Cleaning -35 -30   Cooking -29 -32     As an example imagine Alice and Bob share a flat together. They might randomly assign tasks like cleaning and cooking every week. Maybe Alice usually takes 35 minutes for cleaning while Bob only takes 30 minutes, and Bob takes 32 minutes for cooking while Alice only takes 29 minutes. Let us assume they do not have any preference for these tasks and the results are of similar quality for now. Then Alice will save 6 minutes if she swaps all cleaning tasks for cooking tasks, and bob will save 2 minutes if he swaps all cooking tasks for cleaning tasks.\nRestricting trade in this scenario would make both worse off. So why would people ever choose to disallow trade? One reason Bob might not want to trade with Alice is, because he wants to learn cooking and if he never does it he will never improve. This is probably the main reason nations restrict trade they want to help a local industry bridge the knowledge gap, and while importing cheaper foreign products would be better in the short term it will also cause these local industries to die, preventing this knowledge acquisition in the long term.\nNow one could of course ask: Why would Bob want to learn to cook if he can always trade with Alice? And the answer is already part of the question: \u0026ldquo;always trade\u0026rdquo; - who says that Alice will continue to trade with Bob forever? Bob might want to reduce this dependency on Alice. This dependency is could become a problem for two reasons: Alice may not be able to trade, or Alice may not want to trade any longer.\nCountries are very careful for example when it comes to food and water imports since their trade partners would likely prioritize themselves if shortages would occur. But they are also careful to not be too dependant on other countries since they might use this dependency to their advantage. Trade sanctions are the modern way to exert pressure after all. All these considerations make sense but still result in an outcome which is not pareto optimal.\nNontrivial Exchange Rates     Alice Bob     Cleaning -5 -3   Cooking -30 -33     At the moment we are only trading one task for one, but what if cooking takes significantly longer than cleaning? Then trading one for one is not in Alice\u0026rsquo;s interest anymore. So what would Alice accept? Well in order to break even, Bob needs to offer to clean at least 6 times for every time Alice takes one of Bob\u0026rsquo;s cooking responsibilities. On the other hand Bob will stop accepting the exchange once he has to clean more than 10 times in exchange for not cooking once. So what is fair? 8 because it is in the middle? But then Alice gains 10 minutes by exchanging 40 minutes of cleaning for 30 minutes of cooking, while Bob only gains 9 minutes by changing 33 minutes of cooking into 24 minutes of cleaning. So should we optimize for that?\nOr should we minimize the amount of minutes spent on housework in total? That would mean trading everything which results in a one for one trade which is very disadvantageous for Alice.\nNow for a pareto optimal solution it is enough if Alice does not have any cleaning tasks left because then her situation can not be improved without making Bob worse off. And that will be the case no matter if the exchange rate is 1,2,\u0026hellip; or 10. The question is just how many cooking tasks Bob will have left after the exchange since anything but one for one trade will leave him with cooking tasks left over. So if they just bargain, they will end up with an exchange rate between 6 and 10 which has such a result, so most economists would call it a day.\nComparative advantage     Alice Bob     Cleaning -5 -3   Cooking -40 -30     So what if Bob is faster with cleaning and cooking? Then Alice might still have a comparative advantage for cooking for example. In this example she would be willing to trade 8 cleanings or more for one time cooking whereas Bob would trade one cooking task for at most 10 cleaning tasks. So they can still trade. And this trades makes both of them better off even though Bob is faster at both of these tasks.\nNow if we wanted to minimize the absolute time it takes to do the housework, then Bob should do all of it. But in a free trade situation, that is not what happens. Trade still reduces the amount of housework in total. It just does not minimize it. But at some point the only way to reduce it further is to give Bob more of Alice\u0026rsquo;s work so that point is already pareto optimal since that is not in his interest. And such a point is reached in free trade.\nAlice has, what is know as a comparative advantage when it comes to cooking. While she is not in fact faster at cooking than Bob (Bob has the absolute advantage) she is faster at cooking when cooking is compared to cleaning. This concept first discovered by David Ricardo is an explanation why more developed countries (with machines making both tasks faster) might still trade with developing countries for hand made products.\n    Machine Hand     E -1/100 -1   H -9/10 -1     For further illustration consider a product which is easy to automate E, and a product which is difficult to automate H. Let us say that it takes an engineer 1000 hours to build a machine that builds 100,000 items of product E before it breaks down and it takes 90,000 hours to produce a machine that builds 100,000 items of product H. Hand making these products takes 1 hour per item in both cases. Then product H would cost 90 times as much as product E in a developed nation without trade since the average time required per unit is 90 times as high. But since these goods trade one to one in undeveloped nations, they would be happy to trade H products for at least one E product. From the perspective of a developed nation, they can get product H for \u0026ldquo;dirt cheap\u0026rdquo; from an underdeveloped nation.\nNow here is the thing: Any price between 1 and 90 will result in trade and a pareto optimum. But a price of 1.1 will barely improve the situation of the developing nation while greatly reducing prices in developed nations. This might be viewed as exploitative for obvious reasons.\nBut notice that preventing trade altogether is a poor solution, since that does not improve living conditions in the underdeveloped nation at all. Trade still improves the conditions for both parties. The question is just by how much?\nUltimatum Game and Bargaining So why would the price be so skewed towards one or the other side? A first approximation is the ultimatum game. In this game played by two players, player one makes an offer how a pot of money is distributed between the two. The second player can only accept or reject. If the second player rejects the offer no one gets any money. From a rational standpoint, people should accept any offer above zero. They get money for free in that case it should not matter how much money somebody else gets. And given that player one knows this, the optimal play for them is to take everything assuming a rational player two.\n In experimental settings people did often offer a 50:50 split and offers below 30% were often rejected. There is an ongoing debate why this is the case. It seems that higher stakes reduce rejection rates for example1. I would also guess that not telling player two how much the initial value and the share offered was, and only telling them the amount they would get would change a lot. But that is not really the point here.\n So if you are a corporation and make an offer for a wage, you are kind of player one, so is such an \u0026ldquo;unfair\u0026rdquo; split really surprising? Especially since the free market is specifically designed to apply evolution to corporations leaving only the most efficient and rational ones to survive. Now in reality such a game might sound extreme since people could always make a counter offer. To model this slightly more complicated situation Ariel Rubinstein came up with a bargaining model with an infinite time horizon, where players can make offers and counter offers to split a sum. But the total amount to split decreases over time with a discount factor. This discount factor might represent the cost of not coming to an agreement for some time. This forces the minimal offer to be accepted to be higher. But this minimum is closely linked to the discount factor.\nNow if we would generalize this again and assume differing costs for a delayed agreement and thus different discount factors, it is quite intuitive that the person who needs the money to feed themselves will be much less patient than the party which can wait. This difference in bargaining power results in very skewed distributions of the surplus. Multiple people bargaining games are also discussed in economics, their maths becomes much harder but power does generally fall towards the side with fewer entities on. I.e. the ability to take your business elsewhere generally grants bargaining power.\n Unions, unemployment benefits to fall back on, wage transparency, etc. all increase the bargaining power of workers without setting fixed rates like minimum wages. Although unemployment benefits fail to increase peoples bargaining power if they are conditional on accepting any job offered, since that essentially forces people to accept any offer. So that might actually decrease bargaining power. Unconditional Basic Income (UBI) on the other hand would give people the ultimate \u0026ldquo;F*** you, I can walk\u0026rdquo; card, which makes it quite attractive in my mind. But it might overshoot and actually result in a lot of unemployed people which could then mean not enough taxes to support the scheme in the first place. And if UBI might get taken away at any moment due to being too expensive by the next administration, it does not actually have the desired safety net effect. So I am not completely sold yet.\n You might remember me asking, whether the price should be just the median of the possible interval or the price point where both parties gain the same number of minutes. And while the pareto optimal solution seemed good enough then, you might insist on a more specific solution now. Some might now even have the opinion that the surplus should be distributed with a bias towards the poor. That is a nice notion. But it does not really work. Not only are these benefits hard to calculate in reality, they are often impossible to calculate. To see that, we have to circle back a bit.\nIntroducing Utility to Trade At the beginning of this chapter we assumed that Alice and Bob would not care about the task and only care about the number of minutes. This is generally unrealistic. So now we have to generalize this notion. But since we want to keep the maths light we will instead assume that they will take the same amount of time for every task. So why should they trade? Well maybe they prefer one task over the other. And if they prefer the opposite tasks, they can still trade.\nNow as I argued in the utility chapter assigning utility numbers to certain world states is quite arbitrary, but the indifference curves (sets) are not. And while the marginal rate of substitution is only really defined very locally we will assume for simplicity here, that if Alice is happy to swap cleaning for cooking 2:1 in some world state, she will be happy to do this exchange in any other world state too. This means we assume linear indifference curves.\nThis is not realistic if people like variety for example, then it depends how many tasks of a particular type they already have when they decide whether to trade them. But for the point I am trying to make such a complicated utility function would only make things difficult to understand.\n    Alice Bob     Cleaning -10 -4   Cooking -2 -10     So here is a simple example. This times the number do not represent minutes but utility. But similarly to before, Alice can simply swap her cleaning tasks for Bob\u0026rsquo;s cooking tasks and both would be happy. But what if we modify those utilities a bit. What if Bob does not actually dislike cooking all that much?\n    Alice Bob     Cleaning -10 -4   Cooking -2 -2     In this modification Bob would not want to trade away a single cooking task for a cleaning task. So this trade would not happen. But he would be willing to trade away two or more cooking tasks for one cleaning task.\nAlice on the other hand really dislikes cleaning so she is willing to trade up to 5 times cooking for one of her cleaning tasks. This means there is still a range where both parties would be willing to trade. But the rates would have to be between 2 and 5.\nAnd here is where the issue lies: there is no difference in preference for Alice in the first example and the second example. But in one case she trades a cooking task one for one and in the other case one for two or more. Now Bob from the first example might get the idea to present as Bob from the second example to get this improved conversion rate. There is no way for Alice to tell the difference since we are strictly talking about preferences which are completely subjective.\nAnd for this reason Alice in the second example might refuse a 2:1 trade because she distrusts that Bob is telling the truth about his preferences and wants to avoid getting screwed over. So Bob with preferences from example 2 might not even offer this exchange even at 2:1 (which would not benefit him at all and only leave him indifferent), because he does not want to come across as greedy.\nSo people sometimes avoid trade to avoid social drama even though this trade would in fact make everyone better off (constitute a pareto improvement). And since preferences are hidden, trying to balance the benefits is a completely hopeless endeavour.\nAnd we have excluded different levels of quality/effort completely from the equation until now. Whoever thinks that letting an external observer assign payoffs is fair in any way, has never been part of a group project.\nFair Wages And corporations are really just big group projects. In the beginning you do not have any money so you split (ownership) shares equally (or try to balance them based on contributions). People who join later will at first likely be compensated with stock options as well, but gradually the share of the wages in the compensation package will increase. And here is the thing, equity is a lottery ticket. Most of the time startups fail, but some of the time they take off. Sure stocks will suddenly be worth a ton which is probably not a fair share of the work they did. But the amount of money lottery winners get is also in no way proportional to the amount of money/work they put into it. But you still can not take that win away - otherwise nobody will play the lottery anymore. More on that in Risk.\nBut the funny thing is, that the winners of that lottery tend to attribute their success to their own genius and hard work and overlook the amount of luck they had. Additionally they get used to having money. Both of these factors likely makes them quite confident in negotiations which means that company leaders continue to take a large percentage of the surplus even after the company becomes established and the risk is a lot lower. This in turn means that it becomes common practice to pay a lot for leadership positions, which gives ammunition for comparisons in salary negotiations further cementing extremely high salaries for leadership.\nMoney Before we get to risk, I want to touch on money to make examples easier. So what is money? To answer that question let us get back to our flatmates Alice and Bob. Now let us assume they have a system where they just deal with housework as it comes up (e.g. trash is full), take care of it and entry the time it took into a ledger. They want to have an equal partnership, so they want to keep track of the difference. For this reason they tally up the total contributions from time to time.\nThey use this system for quite some time and the numbers get bigger and bigger. But since they have approximately contributed the same only the lower digits really matter. The current state might be something like 1034 and 1038. They then decide to just remove 1000 from both tallies to make the numbers shorter again.\nTo save rent, they end up adding Charlie to the flat. Now at some point Bob notices that the washing machine is finished and hangs up Alice\u0026rsquo;s clothes. After he finishes he walks to the ledger and starts to write 10 minutes in his column. But then he pauses and realized that this action did not benefit Charlie and if he would increase his tally, then the difference between them increases so Charlie would be required to do something to make up for that at some point.\nAfter a discussion, the flat adds 5 minutes to Bob\u0026rsquo;s tally and removes 5 minutes from Alice tally. They reason that now the difference between Bob and Charlie might increase by 5 minutes but the difference between Alice and Charlie decreases by 5 minutes which means Charlie is unaffected by this change in total. The difference between Bob and Alice on the other hand increased by 10 minutes which is exactly the time Bob spent on a task for Alice.\nIn the future they know how to deal with person to person transactions. Simply add half to one account and subtract half from the other account. If we sum the total amount of time between all flat members, then a person to person transaction does not change this total amount.\nNow it is pretty easy to see how this is pretty much equivalent to fiat money. The group as a whole can simply print it or take it out of circulation by removing e.g. 1000 from everyone (which is what taxes can do). While individuals can only exchange it.\nNational Debt Now the amount of debt the group (state) has does not really matter, but it does matter how the money distribution looks. If everyone has 10xx amount of money, then the state can easily reduce the amount of money in circulation by reducing the balance of everyone by 1000 leaving them all with xx. But if just on person has a ton of it, this debt reduction becomes more difficult. Because you can not just take 1000 from everyone now, because the other people do not have that. Now the rich person might be scared that the group might just default on them. So they might stop valuing the amount they have at the actual minute face value since there is a probability they will never get that back. So the value of their money decreases.\nThey might be willing to spend 20 minutes of \u0026ldquo;ledger money\u0026rdquo; to get someone to do 10 minutes of work. Because then they get at least 10 minutes back and they are not sure if they would see any of it if they continue to have so much in comparison. What is happening is inflation.\nNow in the real world you can not see everybody\u0026rsquo;s balances, so how can inflation be tied to inequality? Well you can not continue to spend (interpersonally) once your balance reaches zero, so the inequality is capped by the amount of money in circulation. If you increase this amount of money in circulation then you increase the cap on inequality, since now people can spend this additional money until they are at zero again resulting in a larger difference.\nNow the time where these inequality problems become most apparent is when you try to slash the money in circulation. Because at that point some people might just be too poor for that. For this reason the money system is generally more stable, if you never actually change the amount of money in circulation. Instead the group stops financing group projects by issuing money and finances them by taxes directly (i.e. move the money slashing together with the spending).\nIn reality one can of course go below zero when it comes to money. But since going even lower increases the spread further and increases the chances of default, this \u0026ldquo;going below zero\u0026rdquo; is only possible when someone vouches for you. I.e. gives you credit. You can then go below zero, but if you can not repay that money your creditor has to balance your books. Now to avoid the creditor vouching for too many people, you kind of have to mark the money they used for vouching. For this reason credit is generally structured such that the creditor hands over money to the debtor and gets an IOU for this money.\nAnyway, this means that the real national debt is actually the \u0026ldquo;national debt\u0026rdquo; plus the amount of money in circulation. And money is nothing but debt. This also means that anyone can really issue money - it is called a coupon or IOU. But debt issued by the entire group (nation) is just more reliable and universally accepted than the coupon for an ice cream at Joe\u0026rsquo;s lemonade stand.\nMoney Supply and Velocity Assume that Alice likes to do housework in the beginning of the week while Bob likes to do it at the end. They started to use a group account to avoid issuing money all the time and this group account is filled by taxes at the start of the week. Assume that the group account is at 60 at the start while Alice and Bob are at zero. Alice does her housework in the beginning of the week leaving her account at 30 in the middle of the week, the group account at 30 and Bob\u0026rsquo;s account at 0. In the end of the week Bob does his tasks and earns the other 30 from the group account. Then at the very end of the week both are taxed 30 and the next week starts.\nSo now Charlie joins the flat. Since an additional person is causing dirt and thus housework, the budget of the group should to increase. But the budget is already the entire money quantity. So taxes can not be increased above 60. Alice suggests to continue spending 60 for now as they do not have a better idea. They reason that the taxes are going to be 20 at the end of the week, so they know that they should do 20 minutes of work each. At that point Bob argues that he already made a time slot for 30 minutes and that they could just entry 2/3 per actual minute. Then everyone would work 30 minutes but they could still work with only 100 money minutes in circulation.\nWhat just happened is called deflation. The value of one unit of money is now worth 1.5 actual minutes of work. Now in reality people do not sit down together and decide for deflation to happen, but the mechanism is similar. The quantity of money is not enough anymore to support the number of transactions necessary. This means that the production capacity of some companies is unused. To avoid this under-utilization they reduce prices. The opposite happens when there is too much money around.\nSo how much is the right amount if we want price stability? To answer that question, notice how the nominal GDP (the sum of all transactions) per week is roughly equal to the total amount of money here. Because money is used roughly once per week and then reused. The number of uses is the money velocity multiplied by the total money supply is necessarily equal to the nominal GDP. The real GDP is the actual minutes of work done per week. The price level multiplied with the nominal GDP is equal to the real GDP. So if we want to keep the price level stable we have to keep the nominal GDP equal to the real GDP. The money velocity is generally determined by things like wage cycles, tax cycles, etc. and thus not easily (sensibly) influenceable. So the sensible thing to do, is to adjust the money supply to the real GDP if one wants stable prices.\nNow some might question why stable prices are desirable. And the answer is pretty much fairness. If you worked 2 minutes to get 2 credits, it is only fair if you can exchange those 2 credits for 2 minutes of work in the future. Inflation takes away value from these credits, deflation adds value to these credits. For this reason I find deflation much worse than inflation, since deflation adds value to existing wealth increasing wealth disparities while inflation works more like a wealth tax (although note that it only taxes actual money and not other forms of wealth). For this reason I find a small predictable inflation rate to be optimal. It is a constant force eating away at inequalities stabilizing the monetary system which is destabilized by these inequalities. But it is not large enough to be relevant to normal money use (i.e. use which does not consist of hoarding it).\n This is the main reason I am skeptical of \u0026ldquo;proof of stake\u0026rdquo; cryptocurrencies still. While they solve the abhorrent energy use problem of \u0026ldquo;proof of work\u0026rdquo; crypto, they still plan on a fixed money supply independent of the GDP. And since the real GDP tends to grow, this naturally results in deflation. In fact the entire \u0026ldquo;investment promise\u0026rdquo; of crypto is, that more people will join (thus increasing \u0026ldquo;its GDP\u0026rdquo;) making existing holders rich by deflation. That is not a healthy. The gold standard has the same problem and its supporter seem to be from a similar crowd.\n Small Excursion on different Money Supply Levels As already mentioned the restriction that your balance can not drop below zero is somewhat lifted by credit. The creditor basically vouches with their own money for the debitor. The debitor can use the money the creditor provides while the creditor receives an IOU which is basically money too, since money is just credit. In the real world most people have their money in a bank and allow it to lend out its money (i.e. act as creditors).\nNow assuming that everyone would have their money in the bank, the bank lends out the money this money is then deposited into the bank which means it can act as a security to vouch for some other creditor again. This means that money is lent out multiple times creating many IOUs in the process. Since the IOUs (the account balances of the banks) are treated like money and generally outnumber \u0026ldquo;actual money\u0026rdquo;, they are called the level 1 money supply (M1), while the \u0026ldquo;actual money\u0026rdquo; (i.e. central bank issued money) is called M0. There are additional increasingly large volumes of money supply with decreasing amounts of liquidity.\nTo keep M1 in check banks can not lend out the full quantity of money deposited and have to retain a certain reserve percentage. This reserve requirement was reduced in 2012 from two to one percent in the european union for example.\nCentral Banks often do not actually adjust the M0 money supply and try to adjust the money supply by influencing the M1 money supply. This can be achieved by adjusting interest rates which in turn adjust the amount of borrowing happening which then influences M1.\n I am not sure why to be honest. It seems much more effective to stop trying to decrease interest rates and actually print money if decreasing interest rates fail to work (as they seem to). If people do not want to borrow more you can not force them to.\n Risk Our ordinal utility function has served us well until now. But in order to deal with risk we need to make more assumptions. To assess risk, it is also important to ask \u0026ldquo;by how much better?\u0026rdquo; and not just \u0026ldquo;better or not?\u0026rdquo;. To obtain such a cardinal utility function we first assume that we do not only have preferences over world states, but actually preferences over probability distributions over world states. Now here is the thing, if we have two probability distributions and one happens with probability p and the other with probability (1-p), then this setup itself is a probability distribution over world states too. The property we would like our utility function to have now, is that such a combined distribution\n$$px + (1-p)y$$\nof the two distributions x and y has utility\n$$u(px + (1-p) y) = pu(x) + (1-p) u(y)$$\nSuch a utility function is called cardinal utility and is unique up to linear transformations (shifts up and down and multiplying the function with a constant are still valid). The Von-Neuman-Morgenstern utility theorem states that the following additional assumption on the preference relation is sufficient for the utility function to have this property\n For any world states x, y, z with $$x\\succsim y \\succsim z$$ there is a p between 0 and 1 such that $$px + (1-p)z \\sim y$$ which essentially just means that there exists a probability such that you are indifferent between the mediocre world state and the lottery between the good and bad world state.\n Recall that we already assumed connexity,transitivity, and reflexivity. This is not a very strong assumption either. And note that we were only able to construct an ordinal utility function on finite (or countable) sets of world states. Using the assumption above lets us construct cardinal utility functions on arbitrarily large world state sets.\nBut since linear transformations of utility functions are still valid cardinal utility functions for the same preference relation, utility functions are still not comparable under this new assumption.\nRisk Aversion     0 100k 1 mio     utility 0 500 1000     Many people misunderstand the linearity of the utility function with regards to probability to mean that people should be indifferent to risk and only consider the expected value. This is not the case. In fact it is a very common assumption in economics that people are risk averse. Consider for example a lottery where you make nothing 90% of the time and 1 mio € 10% of the time. The expected value is 100,000 € then. But if the utility for the guaranteed prices would be as in the table, the value of the lottery would just be\n$$ u(0.9\\cdot 0 + 0.1\\cdot\\text{1 mio}) = 100 \\le u(100k) $$\nwhich is considerably lower than the utility of the expected value. In fact a function with the property\n$$ u(\\lambda x + (1-\\lambda)y) \\ge \\lambda u(x) + (1-\\lambda) u(y) % = u(\\lambda\\cdot x + (1-\\lambda)\\cdot y) $$\nis called concave. And functions with a decreasing slope are concave. This means that decreasing marginal utility is equivalent to risk aversion. In other words: If the improvement from 0 to 1 mio € is bigger than from 1 mio € to 2 mio €, then you \u0026ldquo;the increase\u0026rdquo; in utility decreases with wealth (i.e. your marginal utility goes down). And in that case it is rational to be risk averse. This means that most people prefer to take the sure expected value rather than the lottery.\nThis is the reason insurance exists. By pooling money, the lottery averages out. Nobody has to pay really large sums of money to cover an accident by chance, instead everyone pays a little bit for sure. Now insurance has operating costs so people have to pay a bit more than the average damages. But since they strictly prefer to pay average damages over the lottery, there is some wiggle room to accommodate fees and still improve everyone\u0026rsquo;s lives. To quantify this wiggle room, economists define the risk premium. Which is the additional amount of money one has to give a risk averse person to make them accept the lottery over the safe value.\n Not everyone has to be risk averse, and there are local situations where a lot of people might not be. A good example might be, that you have the option between a lottery for two tickets and one ticket. Since you would enjoy the show a lot more with company than alone, the second ticket might be worth more than the first, which would make you risk loving in this case.\nLotteries are an easy way to introduce risk. So in that sense lotteries are the opposite of insurance.\n Patience Most people are impatient. If you are given the option for 1000 € now or in a year, almost everyone would take now. In part this is due to the fact, that you can always keep it til the next year. So getting it now must be at least as good as later. But additionally it also provides you with additional options you can do right now. Economists like to model impatience like this. They assume that you have basically the same preferences next year (which is probably reasonable to assume, since that is probably what everyone assumes about themselves), and then they argue that the utility of this year is the immediate utility of the things you do this year x0 plus the utility of what you do next year x1 with a discount.\n$$ U(x_0) = u(x_0) + \\lambda U(x_1) $$\nTo extend this to more than two years, the argument goes like this. We assume the preferences stay the same over time so the utility at timestep 1 is\n$$U(x_1) = u(x_1) + \\lambda U(x_2).$$\nSo if we now plug that into the first formula we get\n$$ U(x_0) = u(x_0) + \\lambda u(x_1) + \\lambda^2 U(x_2). $$\nContinuing with this line of argument we get\n$$ U(x_0) = \\sum_{k=0}^\\infty \\lambda^k u(x_k). $$\nIn other words we assume that the utility value of successive years decays exponentially.\n This assumption is wrong. Experiments show that the discounting for the first year is much higher than for the following years. This means that in year zero a person assumes they will care more about year two in year one than they actually will, which results in procrastinating behavior. A more fitting discount method is thus hyperbolic discounting which is studied in behavioral economics. But since this way of discounting results in time-inconsistent behavior (people break their own plans), people often try to take measures which locks them into their plans. If we assume that people take these \u0026ldquo;rational guardrail\u0026rdquo; measures when making financial decisions it is probably fair to assume exponential discounting in investment theory. Lock-in might consist of a fixed savings plan, etc.\nExponential discounting also makes the math easier. Which is good for an introduction.\n Investment If your discount factor is 90%, then you would be indifferent between 9€ now, or 10€ a year later. If someone else has a discount factor of 95% they would value those 10€ later at 9.50€. So if you will get 10€ in a year, you could sell these 10€ in the future for 9.20€ now to this second person which would make you both better off. Receiving 9.20€ now and paying 10€ a year later is equivalent to taking out a credit with an interest rate of roughly 8.7%. And if you have a discount factor of 90% an interest rate of 11.1% makes you indifferent. Given a discount factor of 95% an interest rate of 5.3% makes them indifferent.\nSince everyone can trade with everyone, available interest rates can in some sense be viewed as the result of averaging the \u0026ldquo;indifference rates\u0026rdquo; from all participating people which are a result of their individual discount factors.\nThere are a couple more complications like the fact that lending interest rates are often not equal to saving interest rates and people can not borrow arbitrary amounts of money. People usually do not lend out money to other people for them to use it for consumption. Because if people were going to borrow at these rates due to very high impatience, then they are likely to delay repaying this credit as long as possible.\nSo a different view to deduce interest rates is an equilibrium of available investments. Assume that you could buy a machine for example, which makes your work easier. Let us say it makes you twice as productive the next year but costs you time to build this year. Without the machine you might be able to produce goods of value 10 this and next year. With the machine you might only be able to produce goods of value 1 this year, but due to the doubling in productivity you can produce a value of 20 next year. Now if we want to compare those two scenarios we somehow have to determine a total value over all years. But as we already established, returns in the future are less valuable than returns now. So one has to discount the future year. Now we are indifferent between both scenarios if\n$$ 1 + \\lambda 20 = 10 + \\lambda 10 $$\nwhich is the case for a discount factor of 90%. In other words this investment opportunity is equivalent to an interest rate of 11.1%. So if you need funding to cover your first year of being unproductive while producing the machine, you can offer this interest rate at the maximum. In reality many different projects are funded. Investment projects are willing to accept different types of interest rates. If you sum all projects which are wiling to accept an interest rate of r and plot this number of projects against r, then the number of projects will decrease with r. On the other hand people who are willing to delay their consumption and provide the funding if they get an interest rate of r is going to increase as r increases above their indifference interest rate of more and more people. At some point the demand for funding equals the supply for funding which is the equilibrium interest rate.\nIn short: People more patient than available interest rates will provide funding at these rates for projects which yield at least these rates. While people less patient than these rates will generally not save money, but are also not able to borrow, because they are likely to still be impatient in the future and thus never really willing to pay it back.\n Note that hunger generally reduces patience - patience might be determined by circumstances more than anything else and should not be viewed through a moral lense in my opinion.\n Companies Risk Reduction For now we have ignored risk. We have to add that back in, since that is usually a large part of investments. Since we assume that people are generally risk averse we can assume that it is best if we can reduce risk.\nIf you were a trader in the middle ages for example you might buy a ship yourself and hope it returns from its trade trip. Alternatively you can group together with other merchants and buy multiple ships as a group. Now ships returning becomes statistic and the risk goes down. You then simply call this group a company and everyone receives \u0026ldquo;shares\u0026rdquo; of this company according to the money they contributed.\nBut even with this bundling of risks there will still be risk left over at the company level. Now you could buy shares of different companies to balance out risk even more but even then you will be left with systemic risks which affect the entire country/world.\nSo additional to the interest rates to balance out impatience, interest rates for risky projects are higher not only to yield higher returns in the case of success to balance out the low returns (or losses) in the case of failure, but also to provide a risk premium (which is necessary to make risk averse people invest). Due to these risk premiums one should expect that the group of relatively risk loving individuals (still risk averse but less than others) will be richer on average. But their wealth will also have a larger standard deviation.\nSo there are three things which make you stupidly rich: patience, appetite for risk and luck. And these are usually the attributes of self-made billionaires. They traded free time and comfort in the beginning (starting in a garage, long work hours, sleeping in the office, etc.) for lottery tickets (stock in a company) for future wealth.\nThey are especially risk loving since they can not even diversify. They actually only hold stock of their own company for many years.\nLiquidity So you invest into a company and receive stock in return. But what if the company only makes profits in two years and you need the money in one year? Here the stock market comes in. Because somebody else might be willing to delay their consumption in the second year - so they can take over the investment for you. They then buy the stock from you - at a higher price because they do not have to wait two years till the payoffs anymore. Company shares thus allow people to decide how much and for how long they want to invest and companies to decide how much and for how long they need the money somewhat independently. Because the underlying money can simply be exchanged.\nBut since expectations can change very quickly and the worth of a company is simply the value of their expected future returns their value can swing wildly in the short term. So you might not always be willing to buy or sell which means that stock is still less liquid than a bank account with fixed but lower interest rates.\nCompetition In Why Trade is Good I already argued why determining a fair wage is really complicated. A wage is the product of a negotiation taking into account minutes worked, quality of work (also influenced by past investments into education), preferences for different types of work and lastly bargaining power. Now it is unfortunate that bargaining power plays such a huge role in determining wages, but we already discussed that, and I am not aware of any way to fix that. But additionally it is really a separate issue.\nSo for now let us just assume for simplicity that everyone is equal and earns a wage proportional to their amount of work. Since they exchange their work minutes one for one in this case (again look at introducing utility to trade for generalization), the sum of work minutes needed to produce a good determines the price (i.e. the number of work minutes) the buyer has to give up in exchange for that good.\nIt should be quite obvious that the price should not be lower than the sum of work minutes needed to produce the good, otherwise people would buy it which would not be willing to give up that much free time for it which is not sustainable from a global perspective if people exchange their time one for one. Similarly the price should not be higher than this cost, otherwise people who would be willing to expend the effort needed to produce the good could not get the good which makes them worse off than they need be.\nSo what we want is two things:\n Costs should be minimized (find the production method which minimizes the work minutes needed to produce something - assuming constant quality) Prices should be equal to unit costs to guarantee a pareto optimal production quantity where only (all) the people willing to expend the effort to produce the good actually receive the good  The Trouble with Fixed Cost These are the necessary requirements to ensure pareto efficiency. Before we discuss how to achieve these goals, let us first touch on what is included in \u0026ldquo;costs\u0026rdquo;. Until now I hand-waved it to be the sum of all work minutes needed to create a product. But if we look a bit closer many production processes have an initial investment part and a production part. The initial investment involves developing the process itself and building machines if appropriate.\nAs we have already argued, investment is not free (you have to pay someone for the money - i.e. to delay their consumption) and the risk that the development does not pan out has to be covered as well. So you will have to pay interest on money investors provide. These are \u0026ldquo;capital costs\u0026rdquo;. In the real world capital costs can be interest on credit or dividends you pay shareholders both are capital provided by investors, although credit has less risk involved so interest rates are usually lower than dividend payments per share on average (averaging over multiple companies and time). The second component is labour costs which are self explanatory.\nNow while machines will eventually break down and thus produce only a limited amount of products, development of the production process is truly a one time effort. So we have to make a difference between fixed costs and variable (or marginal) costs.\nA good question you might now ask is: should the price be equal to the variable costs or the average costs (including the fixed costs)?\nThe answer to this question is tricky. On one hand the production costs have to be covered. So if everyone pays the average costs production costs are just covered. Variable costs on the other hand do not include fixed costs and are thus lower than average costs. So if prices were equal to variable costs, the total costs could not be covered.\nBut if the price is above the variable cost, then the life of a person who would be willing to pay less than the price but more than the variable cost could be improved without making a loss. This means that any price above variable cost is not pareto efficient.\nThere are two solutions to this problem. The first is price discrimination i.e. asking for different prices from different people. Now the average price charged still has to be equal (or larger) than the average cost. Which means that in the limit every, single person has to pay exactly their willingness to pay if that just covers all the costs. This is of course not realistic in the real world.\nAnd while corporations already discriminate on occupation (e.g. student discounts), discrimination based on IP address or similar is generally viewed as creepy. So there are limits to what is possible there.\nSo what is the other solution? The other solution is that the fixed costs are payed for by somebody else than the corporation. Maybe everyone pays for it through taxes. This means that some type of product is subsidized by people who do not necessarily want that though. If you just want to achieve pareto efficiency this is not a problem. Taking away something to gift somebody else does not prevent you from achieving pareto efficiency. But it is still questionable whether that is ethical.\nAdditionally there are practical problems:\n How do you determine the size of the fixed costs from outside the company? If you simply ask the company, it has huge incentives to exaggerate them. How do you determine which companies to fund? If you fund everyone then you end up with a ton of companies (each on of them with potentially huge initial costs) which might sell very few products - not exactly cost minimizing.  So both approaches do not really work. So what options do we have?\nMinimize Cost If multiple companies offer the same product and the price is larger than the average cost, then it makes sense for a single company to slightly reduce the price which reduces their income per product only slightly but massively increases the number of products sold as they undercut everyone else. But since ever other company has the same incentive they will try to do the same and the companies bid lower and lower until they hit the average cost floor.\nThis simple model is called Bertrand Competition. A more sophisticated model is Cournot Competition which takes into account one can not just see the price of a competitors product and immediately undercut them because you can not magically conjure up all the devices you would sell when you undercut their prices. So instead of optimizing over prices, companies determine a quantity of products they produce beforehand. And when they produces these the price will fall until all of them are sold. This does not necessarily mean that the price falls down to average cost.\nBut as the equilibrium price in Cournot competition decreases with the number of firms participating. And companies will enter the market until the next entry would reduce the price below average cost. But the price can be considerably above the average price before this entry. Potential founders just know that there is not any space left for an additional company.\nSince the next entrant would move the price below average cost, it is probably fair to assume that the price was already close to average cost (although there are probably examples for extreme cases where this is false).\nNow if variable costs are high and fixed costs small, average costs are roughly equal to variable costs. This means that the price variable cost equality is almost satisfied. And if someone has an idea for a production method with lower costs, they can always create a company out-competing the existing companies with lower prices. And even if nobody entries the market, the potential for competition keeps companies innovating to preempt these entries.\nBut if fixed costs are high, the spread between average can variable costs is high, which means that many people do not buy the product even though products could be made for them at a price lower than what they ware willing to pay. And additional to this problem, the number of companies in the market will be small, because every company that enters considerably increases the average cost since the average cost consists mainly of fixed cost. In the extreme case there are no variable costs (e.g. software) and only one company offers the product. If another company now enters the market the total costs of the entire industry will double (two times the fixed costs) and if the prices do not go down enough to also double the number of consumers, the average costs will be higher since twice the cost have to be divided through less than twice the number of consumers. So not only does the price go down but the average costs also increases. This means that this entry could actually move average costs above the price in one big movement.\nThis means that the second company would never enter, even if the monopoly asked for a price like double the average cost.\nIn other words, when fixed costs are high:\n prices are too high resulting in a loss in pareto efficiency due to people not buying who would buy at lower prices and companies make profits beyond profits covering capital expenditure (compensation for consumption delay and risk). Note that both are accounted as profits (accounting profit) and the surplus profit (beyond fair compensation for delay and risk) is called \u0026ldquo;economic profit\u0026rdquo;. since only very few companies will remain in equilibrium (due to high fixed costs) capital expenses due to risk are very high because most startups in this space will fail as only few companies will remain.  This also explains the extremely high price to earnings ratios and high profit margins in the tech stocks. And since fixed costs keep rising as more and more things are automated I expect PE ratios and margins to continue increasing.\n   What could possibly go wrong? Competition is an evolutionary algorithm for cost reduction. It will do exactly that. Whenever you create an algorithm for minimizing something you should be very aware of unintended consequences since the minimum might not have the properties you like. E.g.\n  letting students optimize their grades does not necessarily result in optimal learning. They will take shortcuts if you make them available\n  letting a reinforcement learning algorithm maximize points in a boat race might result in the algorithm collecting boost spawns at the side of the race instead of actually winning the race2.\n   it is therefore critical to understand what minimizing costs might look like. If this minimization process might cross lines you would rather not have crossed you should create regulatory restrictions there. Companies might also not take into account external costs. Emitting CO2 causes somebody else costs but not the company itself, so it is not taken into account. By creating a tax on CO2 the company actually has to take these emissions into account and the optimization algorithm works again.\nThe process of taxing companies for causing external costs is called aptly \u0026ldquo;internalizing the externalities\u0026rdquo;. Whenever such externalities are discovered taxes equal to these externalities should be implemented to internalize them. If that is done the optimization algorithm works properly. Whenever you have to ask consumers to ignore this optimization algorithm and not buy the cheapest product, the state has not done its job, of properly specifying the optimization problem. In some cases it is difficult to estimate these external costs. This is the case for CO2 as well. In that case one can use certificates instead. They work quite similar to taxes but set the total quantity instead of the cost (see Why Certificates are the Right Tool for Limiting CO2 Emissions).\nThere are also sectors where there is not much room to optimize but many ways to cut corners you do not want cut. In nursing the only cost is working minutes of nurses. So the only way to cut them is to reduce their working time per patient (or reduce their wages) - or build nursing robots. But since nursing robots are still far in the future, do you really want to let an optimizer lose on a problem you know there should be no way to reduce costs of? Because any cost reduction this optimizer finds is bound to be unintended.\nOther Options I stated multiple reasons above, why you might be unhappy with a free market. So what are alternatives?\nPlanning/State owned Enterprise Advantages\n Price can be set equal to average cost or even variable cost and fixed cost funded by taxes  Disadvantages\n No incentive for innovation. No bureaucrat gets fired for doing things the way there were always done. No motivation to reduce costs or keep costs low.  Example: Space X\u0026rsquo;s dramatic launch cost reduction by actually trying reusable rockets.\nSee also Why Communism is not discussed in economics.\nNon-Profits Advantages\n can compete with other non-profits prices are set equal to average cost  Disadvantages\n prices can not be set to variable cost and average cost are still not pareto optimal as non-profits can not make accounting profits either, they have a hard time accessing capital (as they can not pay shareholders for delayed consumption and risk). So they can only take on credits from banks which need to be unexposed to risk so the non profit needs to have enough capital as a security for those loans. They are thus bad at capital expensive tasks.     https://doi.org/10.1257/aer.101.7.3427 \u0026#x21a9;\u0026#xfe0e;\n https://openai.com/blog/faulty-reward-functions/ \u0026#x21a9;\u0026#xfe0e;\n   ","date":"2021-04-15","permalink":"https://www.unassuming.page/blog/economics/economics_101/","tags":["economics","education"],"title":"Economics 101"},{"content":"This article is supposed to be a crash course in financial markets. Discussing the most important financial instruments with their intended usage and some of their unintended usage.\nPositive Expected Return Investments Let us say, you buy a robot able to pick apples for 100k € from person A. Over the year this robot picks apples netting 20k € in fees you earn from the apple plantation owners renting out your robot. For simplicity let us first assume the robot does not deprecate in value. If you now resell the robot to person A for 110k €, then person A made 10k €, and you made 10k €. Everyone is better off in this case. I.e. people make a profit on average and can thus expect a positive return on average when investing.\n1. Equity Equity is the actual ownership of an \u0026ldquo;asset\u0026rdquo; which generates these returns. Like the robot in the introductory example. Quite often a single investor can not afford the amount of money needed to facilitate production though. So quite often multiple investors group together to finance such an endeavor, call it a corporation and own shares representing the amount of money they contributed. If there are profits (after debt is repaid) these profits are distributed according to these shares.\nA possible issue with investments is, that you might not get the returns when you need money. So trading shares enables people to stay relatively liquid while investing into companies. But they still might not get a price they like. This is similar to buying and reselling a machine but better as the actual machine does not have to be moved. The shares of public companies can be traded at the stock market, which means public companies have to disclose a lot of information by law to protect small shareholders, while shares of private companies can only be held by accredited investors and only be traded directly without an established market. Accredited investor basically just means \u0026ldquo;rich enough that you will have to handle the increased risk of private companies by yourself - no hand holding\u0026rdquo;.\nBut there are some platforms (like wefunder, startengine, etc.) trying to provide access to investments into private companies for smaller investors.\nWhile our introductory example was pretty much risk-free, investments usually involve a lot of risk. For example one might start a corporation aiming to develop such an apple picking robot. If they are successful they might sell the usage of their patent. So after an unknown development cost (in wages for the researches and material costs), there might be payoffs which are much higher than these initial costs which can be distributed to the investors. It might also fail, but on average it will return a positive amount.\nTo reduce the risk involved, investors want to use the law of large numbers and diversify (hold shares in various companies). This reduces the variance in their returns and causes their average return to be closer to the expected return.\nDiversifying across different companies and sectors can reduce some risk, but not systemic risks which affect all companies (financial crisis, pandemics, wars, etc.). Holding equity over a long time also averages returns over time, which will average out the systemic risk.\nDiversifying across different companies can be simplified by buying\n Actively Managed Funds: actively managed baskets of shares of different companies. Since the manager of the funds have to be paid, these managed funds have comparatively high fees Index Tracking Funds an un-managed assortment of companies which buy companies included in some index which represent different market segments (e.g. the 500 largest US companies (S\u0026amp;P 500), the 30 largest German Companies (DAX), etc.) which have relatively low fees due to their un-managed nature.  2. Debt Comparatively risk free for the investor who is entitled to a (fixed) interest rate on the issued debt and its full return at the end, unless the debtor goes bankrupt. This financial instrument obviously yields positive returns for the investor and generally also benefits the debtor as they were willing to accept the terms of the credit knowing that they would have to pay interest. So they will generally need the money now more than later e.g. for an investment into a machine. Which will yield more than the interest they have to pay.\nCorporate or Government Bonds This type of debt can be traded on the stock market similar to shares. But in contrast to shares, the return is determined (rather than dependent on the performance of the company).\nLoans and Banks Another form of debt are loans issued by banks, for companies and individuals. Commercial banks (in contrast to investment banks) are not allowed to buy equity with the deposited money due to its higher risk, so this is the way most of the money deposited at a bank is used.\nWhile Bonds are usually issued by institutions with high visibility, loans are issued to much smaller entities, since their credit risk can not be assessed as easily. Few people would buy bonds of Jane Doe at the stock market. The purpose of Banks is to provide this risk assessment and abstract away the lending process into a fixed interest on money in the account.\nBut this also means that they will offer the lowest interest rate on your savings, not only because it is inherently debt you own and not equity, but also because it is more liquid and less risky than any other form of debt.\nBut the fact that banks do lend out your money still means that you could potentially lose it, although many countries take on some of that risk with some kind of investor protection schemes (e.g. up to 100k € is protected).\n3. Other  Convertibles (debt which might be converted to equity at a later date) Leverage (taking on debt to invest into equity, which increases risk for higher expected returns)  Zero Expected Return Investments Imagine, that you would buy the apple picking robot from the last chapter, put it into a cabinet and sell it back to A at the end of the year.\nIf you sell it at a higher price to A than you bought it, then you will make a profit. But A will lose just as much money as you make and vice versa. This is a zero sum game. You can not win anything without somebody else losing. By definition, summing the profits of all market participants of a zero sum game results in a total sum of zero. Therefore the average return is zero as well.\nParticipating in a zero sum game is thus at best a fair gamble (assuming there are no transaction costs). Anything which is a simple \u0026ldquo;buy, store, resell the exact same thing\u0026rdquo; is ultimately a zero sum game. If it is common knowledge that a good will be in more demand in the future because it becomes more useful for some reason, then the price in the present will already reflect this common knowledge/expectation. Nobody will sell a unit of this good for a low price if they know that the price will rise in the future.\nExamples  Commodities: raw materials without quality differentiation (Gold, Steel, Oil, Wheat,\u0026hellip;) Currencies: Foreign Exchange and Cryptocurrencies Options: A contract entitling the holder to the option to buy or sell a certain good or share to the issuer of the option  Hedging (Reason these Instruments exist) If you are a company which needs certain raw materials, it might make sense to buy them in advance/buy futures (a contract which guarantees you materials at a certain price). Companies which produce these materials might want to sell these futures to guarantee a price which is profitable.\nSimilarly it might reduce your risk to hold certain currencies if you are going to have to pay someone in that currency in the future. Converting currency when you accept the contract and not when the payment is due reduces the risk of changing exchange rates.\nIt also means that you might miss out on increasing prices as a seller, or decreasing prices as a buyer.\nOptions are similar, only that they give the buyer the option to buy/sell at a fixed price in the future, but do not require them to buy/sell at that price like a future. This means that you can get the benefits of lower prices as a buyer but do not have the threat of higher prices since you can always buy at this fixed price. The seller of the options on the other hand ends up with all the risk. For this reason they demand a premium on these options which means that they will make money on them on average.\nBut as it is often banks who sell these options, they can suddenly go bankrupt when systemic risks realize. This makes options (and derivatives in general) highly controversial.\nSpeculation Buying and Storing such a good only makes sense, if you know that the good will be more valuable in the future, and know that nobody (or at least few other people) know this yet. Acting on this knowledge will make you money at the cost of less knowledgeable people.\nBut on average people have average knowledge and are averagely intelligent. Speculating on price changes is thus pure speculation. Which is why \u0026ldquo;investing\u0026rdquo; in zero sum games in expectation of beneficial price changes is called speculation.\nPossible Reason for Exclusive Knowledge There are two reason why somebody might have this exclusive knowledge:\n being an insider (e.g. being en employee at a company which produces the good and witnessing a production failure which will constrain the supply in the future and thus increase prices) possessing a better model of the future and thus anticipating future needs better (Dunning Kruger applies)  Takeaways for private Investors Introduction to the Efficient Market Hypothesis (Active vs Passive Funds) If we assume that all shares are held by managed funds, then the sum of returns of all shares, is the same as the sum of returns of all managed funds. Therefore the average return of all shares is the same as the average return of all managed funds. This of course means, that buying a random sample of shares would result in the same returns on average as buying a random managed fund. But in that case, buying the random sample of shares is better, since the actively managed fund causes management fees.\nSo if everyone invested into managed funds, it would be better to invest into an index tracking fund.\nBut if we now assume everyone would invest into an index fund, then the stock price of companies would essentially be random too. And every company which asks for investors would get roughly the same amount of investment. Picking stocks of companies more likely to succeed, should easily return much higher returns than average in this world.\nIn the real world people are not exclusively invested into one or the other. So which one to choose is a more difficult question to answer.\nThe market as a voting machine To understand this question better, it helps to consider why you can not make an above average profit in the \u0026ldquo;active world\u0026rdquo; (where everyone buys managed funds).\nLet us take the shares of company X and consider whether we want to buy them. If we think for example, that the shares of company X will yield a higher return in the future than average, we would want to buy them. If we buy them, we reduce the amount of shares available on the market, driving the price higher. If the price of the shares is higher their return relative to their price goes down. So if you buy enough shares of the company, the price will be high enough at some point, that the return you expect from company X will equal the average return of the market. At that point you stop buying shares of them.\nSo if we assume that everyone else has the same knowledge as you, they would buy the same companies. This means that their price would adjust to the average return quickly. At the time you enter the market the price would already be at the point where you expect the return of company X to be equal to the average return.\nIn a world where not everyone has the same knowledge, people will buy slightly different companies, essentially \u0026ldquo;voting\u0026rdquo; which companies they think will perform better in the future. The end result (the price of the stock), represents the outcome of this voting procedure. If everyone is well informed, it is difficult to be better informed than the average (which is baked into the stock price). But if everyone buys random stocks, it is fairly easy to be better informed than the average.\nThere is some empirical evidence, that buying a passive fund resulted in higher returns than buying a managed fund in the past. This has resulted in an influx of investors to passive funds. As this reduces the amount of informed purchasing decisions, this should enable people to beat the market more easily in the future, which means that the performance of managed funds should increase. At some point managed funds will beat the market by just enough, that they can offset the fees necessary to fund their market research.\nIf their profits go higher, people would return to managed funds, if their profits go lower again people would go back to passive funds.\nSo in some way the share of active to passive funds is an equilibrium as well where the cost of research needs to equal the amount of additional returns. In that world it does not matter which fund a person picks, as the additional returns of active funds are exactly offset by their higher fees.\nSome Personal Opinions  Disclaimer: I am neither your, nor a financial advisor\n Avoid playing zero sum games. You wil lose on average. So stay away from commodities, currencies and options. Whenever you encounter a scheme to make money, ask yourself the question: if I made money with this scheme, where would the money come from? If there is no way all the participants will walk away happily - run! Do not expect to win zero sum games, like you should not expect to win nor play the lottery.\nActive Funds vs Passive Funds Research costs are of course fixed costs, so the larger the sum of money to invest the more attractive it becomes to do some research where this money should be put. This will generally mean that the individual investors should not pick stocks themselves as the effort to do proper research will outweigh the benefits of increased returns. The argument above explains why it probably does not matter whether you pick index funds or actively managed fonds in the (very) long run.\nBut\u0026hellip; if you pick stocks (or funds) yourself and your method does not predict the performance of stocks, then you essentially pick stocks at random (which is basically the same thing an index fund does). So as long as you buy enough (different types of) stocks to average out risks you are not really doing anything different than index funds - assuming your investment strategy does nothing (is uncorrelated to the actual performance).\nNow you could have bad luck and your investment strategy is negatively correlated to performance. But such a strategy could be made profitable by doing the opposite, so it is in some sense equivalent to finding a clever strategy for beating the market. Now, I personally think, that people are unlikely to find a strategy which is actually correlated to the performance of the market and \u0026ldquo;hold it the wrong way around\u0026rdquo;. I mean if you are clever enough to come up with something that actually correlates to performance, you are probably clever enough not to pick the wrong side. In other words: Given that you have a correlated strategy, it is more likely that you actually know what you are doing, than random chance - in which case the strategy will be positively correlated.\nSo if you do not mind spending your own time on stock picking (because it also gets you up to date with the news, because you like doing the research or some other reason), then have some fun. But still diversify and minimize fees by sticking to the stock you bought for a long time rather than switching around all the time.\nBut from a theoretical standpoint you will probably waste your time and could have made the same amount with an index tracking fund without the effort which you could have put into something else.\nYou could also put most of your money into some fund and make an exception for companies you really like. Beware though: While owning stock in your own company might be a good idea because you have inside knowledge and influence on its performance, you are also very exposed to its risk. If the company performs poorly you might lose your employment and your savings. So it might be better to avoid the stock of your own company or even companies in your own area/country in general.\n","date":"2021-04-14","permalink":"https://www.unassuming.page/blog/economics/categorizing_financial_instruments/","tags":["economics","education"],"title":"Categorizing Financial Instruments"},{"content":"I claim that every innovation in human history has decreased the share of variable costs and increased the share of fixed costs. In support of this claim, take a random sample of technologies, e.g. the list of practical technologies on wikipedia:\nGoing through a List of Technologies Prehistoric Era  Stone tools/technology fixed cost of producing the tool, reduced variable cost of doing the thing the tool was meant for. Fire fixed cost of creation and keeping it alive, which increases nutritiousness of food and thus reduces the variable cost of food gathering Fur Clothing reduces the variable cost of firewood to keep warm Mining under the assumption that the resources found will be used to create tools, mining is part of the fixed cost of tool creation. Longboat reduces the variable cost of moving things over water Bone Flute (not applicable) Animal domestication fixed cost of domestication is justified by the reduced variable cost of other food gathering String after the fixed cost of making the string, something else becomes easier (not sure what it was used for) Painting (not applicable) Ceramic (art) (not applicable) Sewing after the fixed cost of learning this technique, the variable cost of cloth creation is lower Rope similar to string Plant domestication similar to animal domestication Brick after the mold is created it becomes easier to create easily stackable stones to build a house. Houses themselves provide insulation and thus reduce the variable cost of firewood etc. Spindle its fixed cost creation reduces the variable cost of cloth creation Metalworking part of the fixed cost of tool creation Salt cultivation the ability to enrich any food with salt would presumably reduce the variable costs of gathering salt rich foods. Leather presumably more durable than other clothing and thus reduced variable cloth creation costs. Irrigation increased yield reduces the variable cost of food creation Equestrianism (Hore Riding) reduces the variable cost of time to move from A to B. Weaving Loom reduces variable cost of cloth creation.  Note: I am ignoring military technologies, because military technology is always meant to reduce the casualties on your side wile increasing deadliness. So it could be viewed as reducing the variable human cost of lives to kill a number of enemies. Sure some of these technologies might have variable costs attached to them (like ammunition) but the cost of ammunition will be significantly lower than the human cost incurred without.\nAncient Era  Writing Systems reduces the variable cost of keeping information alive by oral communication and memorization Mummification (not applicable) Papyrus reduces the variable cost of writing Ard Plough reduces variable costs in food production Wheel reduces the variable costs of transportation Galley reduces variable costs of moving things over water Pottery storing of food reduces the need for constant food gathering Metallurgy/Bronze forging better tools further decrease variable costs Plumbing removes the need for manually removing the waste and thus variable cost Abacus reduces the mental strain for calculations (variable costs) Iron Smelting better tools further decrease variable costs Arch reduce the variable cost to make a bridge, house, etc. Alphabet reduces the number of characters and thus the cost of learning to write Glass making improves insulation of houses and thus reduces the variable cost for heating Steel better tools further decrease variable cost Saddle reduces the di\u000eculty of riding for every ride Lock provides safety while providing a low variable cost of access when in possession of the key Aqueduct reduces the variable cost of transporting water Archimedes' screw reduces the variable cost of transporting water up Caliper makes measurements easier, thus faster, thus cheaper Crane reduces the variable cost to lift something Odometer reduces the variable cost of measuring distances Watermill reduces the variable cost of milling, grinding, etc. Block and Tackle (Pulley) reduces force required to lift something Horseshoe reduces wear (variable cost per ride) Paper reduces the variable cost to write something Aeolipile (Steam Engine) not widely adopted. But later the steam engine will allow for automation, which reduced the variable cost of many things  Honorable Mentions Wikipedias list ends here, but to mention a couple of newer technologies\n Printing Press reduced the variable cost to copy a page Railway reduced the variable cost of transportation Telegraph reduced the variable cost of communication Computer reduced the variable cost of calculation Internet reduced the variable cost of communication again  Information technology is the epiphany of fixed costs. The amount of effort required to build a modern computer with modern software from the ground up is so insane, it could only be achieved by generations of people building on top of each others ideas and existing technology.\nFuture This trend is likely to continue with ideas like self-driving cars, which reduces the number of cars required to serve the same number of people. Further out are technologies like maglev trains in vacuum tubes which would reduce friction and thus energy required to travel to almost zero - at a massive fixed cost of building such a structure. 3D Printing could result in a lot of things being merely a blueprint and material costs. But since it is very slow at the moment, its variable costs are still quite high. Which is the reason it is only adopted in areas where variable costs are even higher (like in prototyping).\n ","date":"2021-04-14","permalink":"https://www.unassuming.page/blog/economics/fixedcost/","tags":["economics"],"title":"Fixed Costs are Increasing"},{"content":"On sunday the game of the \u0026ldquo;Hooligan Eagles\u0026rdquo; against the \u0026ldquo;LesserEvil Hawks\u0026rdquo; is taking place. The city decided, in order to protect the police, it will not send in police to enforce a peaceful game. Instead, it intends to supply the fans of the \u0026ldquo;LesserEvil Hawks\u0026rdquo; with handguns so they can protect themselves against the often violent fans of the \u0026ldquo;Hooligan Eagles\u0026rdquo;.\nWhen the referee takes one of the Hooligan Eagles players off the field for a foul, the camera pans to an increasingly rowdy crowd of Eagle fans close to the Hawks fan section.\nThe viewers sit upright in their sofas as the camera zooms in on a man drawing his gun to prevent an Eagle Fan from throwing a molotov cocktail at the referee. The Fan freezes for a couple seconds looking the gunman in the eye. Then he realizes that he is holding a molotov cocktail with a burning fuse and throws it in the general direction of the Hawks. The gunman is not even close to the point of impact but is startled enough to fire a few precise warning shots hitting the floor right next to the thrower - well at least that is how it looked in his head. In reality the bullet strafes the head of a guy sitting next to his friends two rows below. Startled by the gunshot they turn around and see the bloodstained face of their friend and a bunch men holding guns pointed at them.\nA bunch? Well, remember the molotov cocktail? Yeah\u0026hellip; As they heard about the handgun deliveries to the Hawks the group of friends came prepared. Immediately grasping the situation they take cover and return the fire.\nEscalating Violence With the violence spiralling out of control, the major calls for an emergency meeting. While protesters outside demand an immediate intervention to stop the violence, the chief of police argues that they do not really have the resources to respond to every conflict in every sports game around the country. He also argues that policy casualties would look really bad in the media. So he suggests precision drone strikes and other air superiority measures.\nAs it turns out, firing rockets from wirelessly controlled drones a couple of kilometers above the stadium is not that precise after all, even with all the smart rocket tech and stuff. And most of the people killed are not intended targets.\n documents detailing a special operations campaign in northeastern Afghanistan, Operation Haymaker, show that between January 2012 and February 2013, U.S. special operations airstrikes killed more than 200 people. Of those, only 35 were the intended targets. During one five-month period of the operation, according to the documents, nearly 90 percent of the people killed in airstrikes were not the intended targets. - The Intercept\n As people watch their friends get blown to pieces by rockets raining from a blue sky, it is only a matter of time until a traumatized man blows himself up next to the local police station.\nThe major immediately erects barriers around the stadium to prevent any more terrorists from immigrating. They do not share our values and culture he argues, so they could never integrate into our society. They come from an extremely violent place and we do not want them to bring that violence to us.\nIn response to human rights activists he generously creates an asylum process. It only requires people exiting the stadium to prove that they are fleeing from political persecution and are not just looking for a better life.\nIs This a Fair Comparison? In a classic war, there is a government you can negotiate peace with. If you help the loser back on their feet (with something like a marshall plan) you might actually create a lasting peace.\nBut if your policy is\n We do not negotiate with terrorists\n this is never going to be an outcome. Countries like Germany are not even constitutionally allowed to fight offensive wars. So what is their excuse?\nIf you really want to view it as policing then you ought to behave like a police force. That means protecting civilians at your own expense and not being so liberal with \u0026ldquo;collateral damage\u0026rdquo;. But it especially means that weapon deliveries and air strikes are not a reasonable middle ground at all.\nStay out, or do it properly! It should not have to be said that the current strategy of slowly escalating measures is just as bad as slowly fanning increasing amounts of oxygen into a fire and calling it \u0026ldquo;blowing out the flame\u0026rdquo;.\nFor this reason weapon deliveries and \u0026ldquo;air support\u0026rdquo; is not a reasonable middle ground and a false compromise when asked whether to intervene or not.\n","date":"2020-12-12","permalink":"https://www.unassuming.page/blog/two-cents/recipe_for_endless_war/","tags":["two-cents","politics"],"title":"A Recipe for Endless War"},{"content":" This is a quick and dirty embedding of an older shiny app you can also access in full size  ","date":"2020-10-31","permalink":"https://www.unassuming.page/blog/economics/co2_budget_model/","tags":["economics","politics","climate-change"],"title":"CO2 Budget Model"},{"content":"How much does it cost to become Carbon Neutral? Is it feasible? Or is it too radical? I think that many people paint a grimmer picture than necessary. In fact I would go so far as to say we can solve climate change in our lunch break. Let me explain\u0026hellip;\nI already argued why certificates are the right tool to limit climate change. In this post I explained how certificates guarantee the cheapest transition. But we still do not know how much \u0026ldquo;cheapest\u0026rdquo; costs, right? True, but since we know certificates will result in the cheapest transition, any possible transition we can imagine will be more expensive.\nSo if we just calculate the cost of a transition and use certificates to actually achieve it, then we will basically be guaranteed costs below that hypothetical calculation.\nAn Upper Bound So lets think of a transition where we can calculate the cost. The more intelligent the transition, the cheaper it would be. But a more intelligent transition is probably also very complex and would take way too much effort for my lazy self. So I am not going to think of a clever way to transition to carbon neutrality. Instead I am going to assume the following:\n nobody changes their consumption behaviour no build-out of renewable energy (the same energy mix) all the CO2 emitted will be recaptured from the air  In a sense this is the dumbest strategy one could use. Virtually any other strategy would be cheaper. Renewable energy prices are already competitive with fossil fuels, so transitioning at least old factories is a no-brainer, capturing CO2 directly from the exhaust would be cheaper than capturing it from the air, etc.\nThere are lots of ways to make this cheaper. But all of these ways introduce complexity. And I don\u0026rsquo;t want complexity. I want a quick and dirty estimation.\nSo how can we estimate the cost of this? Well according to a study called A Process for Capturing CO2 from the Atmosphere by Keith et al. in 2018, costs might range from 94$ to 232$ per ton. So lets say 200$ for good measure. How much CO2 do we emit? According to the world bank Germany emitted less than 9 tons/year in 2016 with a downward trend. So that works out to be 1800$ per year and capita to recapture everything.\nLet us put that into perspective: In 2019 Germany\u0026rsquo;s GDP per capita was approximately 46k$. This means Germany would have to spend 4% of their GDP to become climate neutral if we do it in probably the dumbest, most expensive way imagineable.\nClimate Neutrality is Easy To put that into perspective, 4% of an 8 hour workday, is 20 minutes. Which happens to be shorter than our mandatory 30 minute lunch break. So there you have it, if we used the dumbest strategy ever and did not change a single thing about our energy generation, consumption behaviour, etc. we would only have to work 20 minutes longer and this would already work out.\nIn Q2 2020 the German GDP fell by more than 9% due to Coronavirus induced lockdowns. People claiming that Climate Change would be worse than the Coronavirus are kind of off the mark.\nI think it is a bad idea, to tell stories of impending doom and blow the amount of effort needed to avoid climate change out of proportions. If your message is that people need to stop using airplanes and sail across the atlantic instead, then you should not be suprised that people will push back against measures poised to reduce emissions to zero. You taught them to expect these measures to demand great sacrifice. They do not.\nThe pandemic has demonstrated that we can adapt extremely quickly to a new situation. The production of face masks spun up within months to meet global demand, we transitioned to remote work at breakneck speed. If we would set proper incentives (like a price on CO2), transitioning to carbon neutrality would feel like a breeze.\nThe ingenuity of people will probably make the drag these certificates have on the economy hardly discernable from the natural fluctuations of our GDP.\nSo please, please stop fear mongering and simply vote for certificates! Sure we can probably terraform earth back to its previous temperature by scrubbing CO2 from the air later, but this will be much more expensive than what we can have right now.\n","date":"2020-10-31","permalink":"https://www.unassuming.page/blog/economics/econ_impact_of_carbon_neutrality/","tags":["economics","politics","climate-change"],"title":"The Economic Impact of Climate Neutrality"},{"content":"Education is one of those topics, which everyone has an opinion on, and reforms are proposed every other day. In Germany it is even worse, as education is state\u0026rsquo;s jurisdiction, so multiply the mess by 16. So, is this just another proposal which claims to be much better than any others proposed before?\nI would definitely have an opinion to offer. But writing down this opinion is fruitless if I can not substantiate my claims. And this is fundamentally the problem of every proposal. No one has any real evidence. Where would you even get it from? Sure, there are a couple of pilot projects from time to time, where volunteering schools try out a new education model. But even those are not very reliable. Why? Because they volunteered.\nYou see, often the difference between an awkward theatrical performance and a comedy is the confidence with which the actors sell it. And it is painfully obvious if a teacher heavy handedly tries to implements the latest innovation taught in the last seminar they attended. I remember the time when we suddenly had to draw a mind map as an introduction to the topic in every class. So if all pilot projects are conducted by volunteers (i.e. people who believe in the new method) you are going to get much better results than you will get in practice, when the unmotivated teacher next door has to implement them.\nSo one of the biggest problems in education is the lack of data. Additionally you can not make arbitrary experiments out of ethical concerns. You are playing with the future of the kids you are experimenting with after all.\nObtaining Data with Positive Side Effects In my school there was a hallway decorated with quotes. One of them was roughly\n a teacher helps you solve problems you wouldn\u0026rsquo;t have without them\n this harmless joke has a true and problematic core: The teacher is the one, who designs the examination and ultimately grades the students. This is problematic for multiple reasons:\n  a lot of students will try to sabotage lessons by distracting the teacher, since material not covered will not be part of the exam. From a top down view they are of course sabotaging themselves as they prevent themselves from learning. But people are generally not patient enough to look that far ahead. So their objectives are grades. And sabotage is a shortcut to better grades.\n  exams posed by teachers are not comparable. This is ultimately unfair to the students, as anyone looking at the grade will have no idea what that grade actually means. One example from my own experience:\nWe had to choose between Latin and french in 6th grade. Latin was the choice of anyone who didn\u0026rsquo;t really want to learn another language as it promised to be a little bit of history and less vocabulary. This of course meant that our Latin class was atrocious from a language standpoint. To keep grades in a unsuspicious range, exams were ultimately translations of texts we already translated in class, with tons of vocabulary provided in a table on the side.\nTo prevent people from simply memorizing the entire text, some sentences were dropped from the original text. But using the words provided and remembering the story from class, you could reliably puzzle together the translation without really knowing any Latin at all.\nSo now I have a \u0026ldquo;good\u0026rdquo; Latin grade. But does that mean I am actually good at it? Of course not.\n  bad teachers can simply cover up their subpar teaching skills with easier exams.\n  In the last two years of school, the relation between teacher and students greatly improved. Why? Well because we were preparing for the final examination. An examination which was provided from a central authority - well\u0026hellip; central to the state within Germany. Suddenly the teacher was the coach, helping you pass the exam instead of causing your problem. And this flipped the teacher/student relationship on its head.\nCentral Examinations There is no reason not to do central examinations. The cost of mailing around exams is negligible at this point. Simply randomly shuffling exams around the country\n improves the teacher student relationship makes grades more comparable provides data on the effectiveness of teachers and their teaching methods removes a ton of bias against/for students by virtue of anonymity dampens the tendency for grade inflation over time  The only valid concern I heard so far, was that central examinations remove the flexibility teachers have with the syllabus. Since there is value in teachers adapting the syllabus around children\u0026rsquo;s interest. And nothing would be more unfortunate than a teacher shooting down curious questions because they can not afford the distraction from the syllabus.\nBut there is a relatively simply fix for that: Provide a menu of exercises in the exams so that students can pick an area they are strong in/where the teacher focused their lessons on.\nA potential problem with that approach is, that students might always pick the same topic (e.g. always pick probability in mathematics and never learn the basics of algebra and analysis).\nPoints not Grades To avoid this problem you could fundamentally redesign exams. What if you did not have a maths exam, but a probability, analysis and algebra exam and you would only have to take each of them at some point (in no particular order)? Finishing school would then not mean finishing a particular year, but rather achieving a minimum score in all required exams. You could have a progression of increasingly difficult exams in one subject (probability I, probability II,\u0026hellip;) or you could be even more radical and have everyone write the same exam with a selection of exercises of various difficulty. Beginners would do the easier exercises at the beginning, while advanced students would do the more difficult exercises with more points.\nThere is an important side effect of this approach. You can compare a students performance to their past performance more easily as they would be retaking \u0026ldquo;the same\u0026rdquo; test. This has multiple benefits:\n  in general every retake will result in a new high score. While grades measure where you should be by now, scores on such a gradual test would reflect where you are. And it is much more motivating to achieve a new high score than to just \u0026ldquo;stay on the same grade\u0026rdquo; year over year.\nAs students will have to achieve a certain threshold to finish school, there is still pressure to reach certain milestones. And students will inevitably compare themselves to each other. But there is still a much bigger sense of progress, if your score increases every time you retake the test.\n(I would bet that this is one of the reasons why sports are more popular than other subjects)\n  Since there is a minimum threshold of points students need to achieve in order to finish school, they will accumulate roughly this number of points over time. So what if we take the current average cost of teacher salaries per student, divide this cost per student by the total number of points, and pay teachers per point gained of their students?\nAt this point the interest of the student and teacher are perfectly aligned. And aligned interest result in a much more productive collaboration.\n  Since we now decoupled the measurement of progress from the school system, it is possible to loosen the screws on the syllabus. Teachers are free to come up with novel ways to teach their students. As they have a financial stake in the outcome, they will tend to be a bit conservative with changes - which is a good thing, as children\u0026rsquo;s futures are at stake - but if they are sure about something, they can just do it.\nOf course there will be some issues at the start: Maybe gaining points is easier for beginners than for advanced students, causing a windfall for entry level teachers. Or vice versa. Another problem is, that short term point gain might not be conductive to long term learning.\nThis can be balanced out by schools. So instead of paying teachers directly, the schools would be payed the amount all of their teachers earned. Then the school could redistribute these earnings to the teachers. They could just pay every teacher the amount of points their students earned, but they can also introduce additional measures to balance out the highs and lows of point gains over time. Since the school has the macro view as their students stay with them for longer than a year, it will have an incentive to invent measures which cause teachers to prioritize long term learning over short term learning.\nIn total this will result in a rapid trial and error process, where unsuccessful strategies are quickly weeded out, ultimately resulting in much more effective education.\nAn Optimization Algorithm We have designed an optimization algorithm, which optimizes the amount of points gained by students over their time in the school system. It is quite important to note that schools will optimize for points and not \u0026ldquo;learning\u0026rdquo;. And while the points try to measure \u0026ldquo;learning\u0026rdquo; progress, as soon as a measure becomes a target, it ceases to be a good measure (Goodhart\u0026rsquo;s Law).\nFor this reason this measure needs to be a moving target. It needs to be constantly readjusted to actually measure learning instead of \u0026ldquo;something else\u0026rdquo; which might be an artifact of the current measurement.\nSo the measurement should be designed by stakeholders in the outcome. E.g. Universities might desire students to have certain skills when they enter. So they are good candidates to create such measures as they will constantly see the results from students entering their halls. If they notice some skills were neglected, they can adjust the tests such that they test for these skills, which will mean the next round of optimization will put a greater emphasis on these skills.\nCompanies could also top up funding for certain skills, making points in these categories worth more, causing schools to focus more attention on these skills.\nWhy Grades are Unavoidable Okay, so if we have Grades at all, this might be a good idea. But what if you have the opinion that Grades are detrimental to students in general? Did I not just make an opinionated suggestion contrary to what I stated I would do in the beginning?\nWell, if your school believes that Grades are bad, they can delay grading students up until the last year. Then students would take all tests at once and collect all the necessary points at once. This results in a windfall for the school at the end of a students time at school.\nThat is a bit risky to fly blind up until the end you say? Well, it is also risky to never asses a students capability and hoping everything will turn out fine. But if you are convinced that this will improve students performance, you can do it.\nOkay, but what if you wanted to have no grades at all? Well how do you expect universities to select their students or companies to select their employees? If the school isn\u0026rsquo;t doing the testing, then the universities/companies will have to do it themselves. And they will not be able to observe candidates for years. In other words, their judgement will likely be based on a single test. Great way to reduce the pressure\u0026hellip;\n","date":"2020-10-11","permalink":"https://www.unassuming.page/blog/two-cents/better_education/","tags":["politics","two-cents"],"title":"A Better Education System"},{"content":"First of all: A tax and certificate system is equivalent to some degree. The main difference is that taxes set prices while certificates set quantities. But more on that later. And since taxes are easier to understand I will start with explaining them.\n1. Understanding Taxes Assume you tax every ton of CO2 with 100€. Then every measure to reduce CO2 is taken, which is cheaper than 100€ per ton of CO2 and no other measures. In other words. You guarantee that all measures are taken which are cheaper than a certain threshold.\nNow our goal is to limit emissions. So our target is a volume, not a price. So how do you reduce CO2 emissions to a certain volume? Well you could start out with some tax e.g. 50€ and see what the resulting volume is let’s say 100 Ft (Fantasy tons). And the goal is 20Ft. Then you increase the price to 70€. So now all measures are taken which are cheaper than 70€ not 50€. So the volume has to decrease. The question is just by how much? So let’s say it goes down to 50Ft. So you increase the price to 100€ and the volume goes down to 30Ft. So you increase the price again to 120€ and finally the volume of CO2 produced goes down to 20Ft. This seems like a very elaborate process. Is there maybe a shortcut?\n2. Understanding Certificates Instead of adjusting taxes, until the desired quantity is reached, you now instead decide to auction (tradeable) certificates. For an individual company it does not matter whether you pay a tax of 100€ per ton of CO2, or buy a certificate priced at 100€ for every ton of CO2. So what is the difference? Well you release certificates for 20Ft of CO2. During the auction, companies consider how expensive it would be for them to reduce CO2 emissions. So they would bid higher until the certificate price is higher than it costs them to simply reduce their CO2 emissions. So what can we say about the final price? Well we know it already from the tax-case! The price will be 120€. Why is that? Well, assume that the price is lower. For example 100€. Well, we know from the tax example, that people would want to buy 30Ft at 100€. But only 20Ft are auctioned. So people would bid higher. To summarize: all those tax adjustments would happen during the auction. Which is a lot quicker than any policy making process.\nComparison There is no difference for a company whether it has to buy certificates at a certain price, or pay taxes equal to this price. So certificates and taxes are equivalent in this sense. But CO2 certificates allow the state to set the volume, while taxes are good for setting the price.\nBut in both cases the end result will be optimal in this sense: The cheapest measures to reduce CO2 will be taken first. Because all measures below the price/tax will be taken and none above. And while there might be market failures which need to be addressed in some cases, no other policy comes close to this efficiency guarantee.\nSo one should choose certificates if one wants to achieve a certain volume, and one should choose taxes if one wants to achieve a certain price.\nWhat do we want to achieve? Our stated goal is, to limit global warming between 1.5° and 2°C. The IPCC released a summary for policy makers how much CO2 can be released to achieve this goal (what is the budget). So the total volume is given. What is left to do is to distribute this volume over countries and time.\nSee this interactive dashboard for possible scenarios.\n For comparison: the EU emission trading system covers about 45% of the market and sets a reduction rate of 2.2%. In no scenario is 2.2% sufficient. The reduction rate rather needs to be roughly 10%. No wonder certificates were not effective so far. We did not set ambitious targets. Why should we blame certificates for achieving what we asked them to?\n After selecting such a scenario one simply has to emit the certificates calculated by the parameters provided and the market will do the rest.\nSummary Certificates guarantee the most efficient (cheapest) transition to sustainable energy. They allow us to simply input our desired value and automatically set incentives for companies to achieve these values. In this sense climate change is incredibly easy to solve from an economic perspective. The only issue is political will.\nQ\u0026amp;A What happens if a company runs out of certificates? Q: Is is correct, if all certificates for one year are sold, a company without certificates is not allowed to sell their products? (if they do not have measures to set CO2-emissions to zero?).\nA: A company without certificates is a company which did not bid higher, which means the alternative was cheaper (reducing their CO2 emissions). So therefore that company would be able to reduce its emissions. But you can always buy and sell certificates to other companies if you find out later that you misjudged.\nWho needs to buy certificates? Q: How are the CO2-emissions are calculated? Does the bakery in my neighborhood need a certificate or only the big energy/oil companies?\nA: Ideally certificates would cover all CO2 emissions. But in order to avoid the bureaucracy you can do the following:\n Assume that fossil fuels will eventually be burned, and since the amount of carbon atoms in these fuels is known and determine the amount of CO2 released, you can sell the certificates together with the fuels at import time/extraction. Consumers who buy the fuel would not have to deal with certificates because the filling station already bought the certificates with the gas. And simply sells it to you under the assumption that you are going to burn the fuel. So only companies importing or extracting the fuel would actually have to deal with certificates. Caveat: If you are a power plant and use carbon capture, then you bought fuel with certificates, but since you captured the CO2, you did not actually release the CO2 as assumed at the beginning. So in this case (if you prove that you captured the CO2), you can resell the certificate. (In this sense it is quite similar to \u0026ldquo;pre-tax\u0026rdquo;) ","date":"2020-10-09","permalink":"https://www.unassuming.page/blog/economics/why_certificates/","tags":["economics","climate-change"],"title":"Why Certificates are the Right Tool for Limiting CO2 Emission"},{"content":"a lot of people would protest. There are of course more than two colors. For example \u0026ldquo;red, green, blue\u0026rdquo; are already three. Okay so maybe the statement was an exaggeration. How about \u0026ldquo;only 5 colors\u0026rdquo; (Red, Yellow, Green, Blue, Violet)? Some people might start to agree with that statement. Other people might list a few more. At some point words for more colors will run out. Yet some people would still disagree with the statement: \u0026ldquo;there are only x colors\u0026rdquo;. Even though we only have a finite number of words for them.\nWhy? because colors are wavelengths on the electromagnetic spectrum, therefore an infinite number of colors exist. We do not have an infinite amount of words for colors though. So how can we talk about colors, if we do not even have words to describe most of them? We are a bit fuzzy about it. \u0026ldquo;Red\u0026rdquo; is not one particular wavelength but rather a range. But not a range with clearly defined edges. More of a \u0026ldquo;redness\u0026rdquo; distribution over the wavelength were wavelengths farther away from a \u0026ldquo;red\u0026rdquo; core are \u0026ldquo;less red\u0026rdquo; than wavelengths closer to this \u0026ldquo;ideal red\u0026rdquo;.\nSo are (words for) colors really a finite set of fuzzy intervals on the electromagnetic spectrum? No, we still have not captured the full complexity of the topic. As our eyes only have three light receptors, we can not actually see every wavelength. Instead we infer the correct wavelength from all three receptors. Which means we can cheat them with only three lights - computer monitors (This is not Yellow).\nOkay but now we captured all the complexity, right? No. Our brains also try to correct for lighting, which is how the internet debate in 2015 whether a dress was #whiteandgold or #blackandblue came to be (The dress).\nColor is subjective and objective At this point no one would argue that our usage of color names is really objective. There are so many tricks of the human perception in the chain that colors could very well be called subjective. Yet few would take someone seriously who calls their blue shirt green if no one else sees it that way. People with colors between blue and green might get away with defining their shirts color. But if their shirt looks \u0026ldquo;obviously blue\u0026rdquo; you will have a hard time convincing people to call it green.\nOur perception is similar enough, that we treat colors as something objective even though it arguably is not. I would go so far as to claim, that you would be disregarded as an unhelpful pedant if you called a mix of red/green which appears as yellow on a screen \u0026ldquo;red-green\u0026rdquo; instead of \u0026ldquo;yellow\u0026rdquo;. The real question is: is that a bad thing?\nMy answer would be that it depends on context. If you are not in the context of physics or light engineering, insisting on more objective description of color is probably anything but helpful. And our \u0026ldquo;subjective\u0026rdquo; take on \u0026ldquo;objective colors\u0026rdquo; works, as human perception is similar enough to be a good basis for communication.\nColors in the way we use them, are not meant to describe an objective reality but rather an experience. But in order to communicate our experience to someone else, we need to use words in the same way. So you can not simply redefine colors for yourself. Because at that point no one knows what is meant by those words anymore without a lengthy definition process beforehand. This is the reason we might be annoyed at people trying to redefine the color of their shirt. It makes the communication of our experience to someone else more cumbersome.\nApplying the analogy I would guess that this notion of \u0026ldquo;sure, it is not really objective, but it is pretty clear what is mean by that\u0026rdquo; is the reason why some people claim\n There are only two sexes. Sure XX and XY are not the only chromosome pairs that exist in the world, and sure we do not really care about the underlying chromosomes (wavelengths) but rather the appearance of people (perceived colors). But we still insist on this subjective/objective mess of only two sexes (a finite set of subjective but very objective colors) because that simplifies the communication of experiences. So we ridicule you for trying to redefine your apparent sex (apparent shirt color)\n And I sympathize with this notion to some degree. Although I want to stop before the the last sentence - I would rather change my vocabulary if someone insists, than to actively hurt someone\u0026rsquo;s feelings for no reason, even if I think it is a bit silly.\nAnd when it is not immediately obvious (a shirt between blue and green) the person would be asked to define the \u0026ldquo;correct\u0026rdquo; color (sex) anyway.\nThe Sex and Gender distinction  The distinction between sex and gender differentiates a person\u0026rsquo;s sex (the anatomy of an individual\u0026rsquo;s reproductive system, and secondary sex characteristics) from that person\u0026rsquo;s gender, which can refer to either social roles based on the sex of the person (gender role) or personal identification of one\u0026rsquo;s own gender based on an internal awareness (gender identity). - Wikipedia\n As we can see from this definition, the line between sex and gender is not between chromosomes and outward appearance, but between (chromosomes and outward appearance - sex) and (behavior and roles - gender).\nTrying to translate this back into our analogy, \u0026ldquo;colorgender\u0026rdquo; would be something like:\n cold, bland, work - grey warm, love, warning - red etc.  Now is there a need for the word \u0026ldquo;colorgender\u0026rdquo;? Well I don\u0026rsquo;t really have any uses for it. So I do not think that such a distinction between color and colorgender needs to exist. And since this word does in fact not exist, most people seem to agree with me. And I feel similarly about sex and gender. Especially since a list of genders is basically just a list of boxes to put people into. No wonder that people make up new boxes all the time!\nIn that sense genders only really help to reinforce these stereotypes/boxes. So I do not really see a good reason to make this distinction. Which is not made ex ante anyway:\n In ordinary speech, sex and gender are often used interchangeably. - Wikipedia\n And languages like German do not even have two different words to make the distinction.\nSpanning the arch to Pronouns The reason people are clashing so bad over pronouns is that they operate with a very different set of assumptions.\nIn one camp you have people using Gender and Sex interchangeably and using this \u0026ldquo;subjective/objective\u0026rdquo; binary classification. From this set of assumptions it seems quite obvious that there only need to be two pronouns - maybe a third, neutral one. From this perspective introducing new pronouns seems absolutely superfluous and only serves to complicate communication.\nIn the other camp you have people who make a Sex and Gender distinction, where Gender represents boxes of stereotypes. As pronouns are associated with genders, from this perspective the unwillingness to allow for more than two pronouns represents the unwillingness to let people out of theses boxes (gender roles).\nIn some sense it is quite ironic: \u0026ldquo;progressives\u0026rdquo; created boxes with the term \u0026ldquo;gender\u0026rdquo; (roles/identity) and blame \u0026ldquo;conservatives\u0026rdquo; for being intolerant due to their unwillingness to roll with new boxes (new genders) which are a way for people to escape their previously created boxes.\nIt is definitely up there in the list of unnecessary controversies.\n","date":"2020-10-07","permalink":"https://www.unassuming.page/blog/two-cents/there-are-only-two-colors/","tags":["two-cents","politics"],"title":"There are only two colors"},{"content":" Communism is not a bad economic system. It is not an economic system.\n Every economic system is fundamentally an allocation algorithm. Somehow it must be decided what is produced, and who can use/consume that. An economic system is the “recipe” (algorithm) for making this decision. If you specify such an algorithm, you can make statements about the result.\nFor example, Capitalism:\n1. Start Sate: Everyone starts with whatever they \u0026quot;own\u0026quot; and is free to decide what do with it (including their time). 2. Everyone has the option to trade if both parties agree. Continue trading until no such trades exist anymore.  You can then show that under specific circumstances the result of this algorithm is pareto optimal.\n pareto optimal does not mean perfect in any sense. Just not \u0026ldquo;obviously sub-optimal\u0026rdquo;\n The problem with Communism is, that it is an under-specified algorithm. You only state that everyone owns everything. But the question who gets to use/consume these things at any time, and who should work on what thing is not specified. So this “planning” still has to be done somehow.\nAnd since there is no mechanism which would do this decentrally like in Capitalism, it usually ends up being a centrally planned economy. And that requires a planner. The issue here is, that a group of people will never agree on what is best to do for the group. Even if the entire group is completely altruistic. The reason for this is, that no-one knows how other people feel about certain things.\nExample Consider a post-scarcity society of Alice, Bob and Charlie. They have housing, food and all the basic necessities. Now they have to decide what to do with their time.\n Alice is very curious and wants to explore space. So she wants the group to build a spaceship. Bob likes to relax, so he wants the group to build a swimming pool. Charlie is philosophically minded and wants the group to discuss the meaning of life.  Then what should the group do? None of them is egoistical, Alice and bob would be happy to share the spaceship/pool with the group. The issue is that they simply do not want the same things. But if one of them would be the planner, then they would simply decide to do whatever they want to do and impose it on everyone else. You could of course vote on this issue,\n A voting as a mechanism to generate a public preference relation is deeply problematic (see Condorcet Paradox)\n but even if you manage to get a majority for something, it would still result in the majority imposing their will on a minority. Essentially forcing them to work on something they are not interested in.\nSo you might think, that everyone should just work on their own project. But this is a very capitalistic outlook on things already. Since you essentially say: Everyone owns their time and they can do whatever they want to do with it. If you then introduce different skill sets, then it might stop making sense, that people work on their own projects. And suddenly you would have to introduce some form of \u0026ldquo;exchange system\u0026rdquo;. So you would likely end up with the second part of capitalism as well.\nSummary Communism is not an economic system, because it does not specify how people should use resources. And this vacuum is usually filled with a planned economy which is inherently authoritarian to some degree, since the priority list of the planner will never coincide with the priority list of every individual. Therefore it imposes priorities on other people.\nIn some cases, this imposing of priorities might be acceptable. Most people would probably agree that enough food and housing for everyone should be top priority. So you can artificially move these things up the priority list (generated decentrally by the capitalism algorithm), by guaranteeing them with unemployment help or universal basic income.\nChina ultimately decided to use the \u0026ldquo;Capitalism Algorithm\u0026rdquo; for most of its economy, letting it deal with the details. But they then modify the result by heavily subsidizing certain sectors. Essentially planning certain things centrally, while leaving the details to the capitalism algorithm.\nTL;DR: Economists do not discuss Communism, because there is no system to discuss.\n","date":"2020-10-05","permalink":"https://www.unassuming.page/blog/economics/communism/","tags":["economics","politics"],"title":"Why Communism is not discussed in Economics"},{"content":"While most programming languages use 0-based indexing some people are not convinced that this is a good thing and not just the legacy of the language C. They argue that starting to index with one is more intuitive than starting to index with zero, and that there is no good reason to use 0-based indices besides pointer arithmetic which should not be of concern to higher level programming.\nAnd to be fair, proponents of zero based indexing have mostly failed to provide a convincing argument for their preference (Dijkstra\u0026rsquo;s range argument aside). To remedy this, I am going to present 5 arguments for 0-based indexing and address the intuition argument of 1-based indexing.\n0. Intuition Sure if you simply want to enumerate a written list, 1-based indexing makes more sense. 1-based indexing then provides you with the correspondence of the n-th element with the index n. But we do not have to look far to find instances where this does not apply. One simple example are the parameters of polynomials or exponential series to be more general. Mathematicians generally write\n$$a_0 + a_1 x +a_2 x^2 + a_3 x^3\u0026hellip;$$\nstarting with the index zero. And exponential series are everywhere. Sine, Cosine, Fourierseries, Taylorseries, etc. The taylor series brings us to the next class of things you want to index with zeros: Operations you might apply repeatedly. Having the function itself as the 0-th derivative of itself allows one to intuitively place it in the same enumeration as the rest of the derivatives. The same happens when you want to repeatedly apply some operator (e.g. the transition matrix for markov chains). Or any discretized physics simulation starting at (surprise, surprise) time zero.\nAnd there are more places where you just have some initial thing left over which does not really belong into your enumeration. In the case of linear regression, you might have n parameters with coefficients plus a bias. Using zero based indexing, the bias naturally becomes the 0-th element while the coefficient at index i corresponds to the i-th element.\n$$y = a_0 + a_1 x_1 + \u0026hellip; + a_n x_n$$\nSo while there are certainly cases where 1-based indexing might be more intuitive for enumeration, there are just as many use cases where 0-based indexing is more intuitive. And since this is not really an argument for 0-based indexing but rather a counterargument to the inherent intuitiveness of 1-based indexing, it is nice that I had some index left over to start the actual argument for 0-based indexing now:\n1. Pointers The most well known argument for 0-based indexing is pointer arithmetic. Computer memory is enumerated with integer addresses, and a \u0026ldquo;pointer\u0026rdquo; is just a variable storing the address for some bit of memory. If you want to store an array of size n in memory, it is enough to reserve this memory and keep the address to the first bit of memory. If you want to retrieve the second element, you know that its position is right after the second element at address p. Therefore the second element is stored at address p+1. The i-th element is stored at address p+(i-1) and the first element is stored at p+0 because p already points to the first element. So pointers naturally give rise to zero based indexing.\nNow I agree that this is not a good enough reason to use zero based indexing. No one should work with bare pointers in this day and age and programming languages could just abstract such implementation detail away. But I made this point not only for completeness sake, it is also a good introduction to\n2. NDArrays Memory is 1-dimensional. Addresses are just a single number incrementing. A naive approach to store a matrix in memory might be, to store an array of arrays. I.e. an array with pointers representing the columns with every pointer pointing to a row. While this works, it is not very efficient. Not only do you need to store an entire array of pointers, you also have to first retrieve them to find the right row. This means access to an element requires two memory retrievals and memory operations are notoriously expensive compared to arithmetic. It is thus preferable to simply flatten n dimensional arrays. This means that rows are simply concatenated and stored one after the other.\nSo lets see how that would look for a 3x10 matrix in one based indexing\n   col 1 col 2 col 3 col 4 col 5 col 6 col 7 col 8 col 9 col 10    row 1  01 02 03 04 05 06 07 08 09 10    row 2  11 12 13 14 15 16 17 18 19 20    row 3  21 22 23 24 25 26 27 28 29 30   and compare it to a 0-based layout:\n   col 0 col 1 col 2 col 3 col 4 col 5 col 6 col 7 col 8 col 9    row 0  00 01 02 03 04 05 06 07 08 09    row 1  10 11 12 13 14 15 16 17 18 19    row 2  20 21 22 23 24 25 26 27 28 29   You might have noticed that in the second case, the first digit is always equals the row while the first digit always equals the column. So if we wanted to access the element a[i][j] we could simply access a[ij]. Now of course concatenation of numbers is not really a thing unless you switch to strings so the actual operation would look like this a[i*10 + j].\nNow you might argue that this example only works because we are using a base 10 numbering system. This is half right. The concatenation? Sure. But that is due to digits being written as\n$$abcd = a 10^3 + b10^2 + c 10^1 + d 10^0$$\nIf you have an arbitrary n x m matrix, you will still be able to access the element a[i][j] with a[i*m + j].\nI challenge you to try and come up with the bijection for 1-based indexing without converting everything to 0-based indices and back. It is quite difficult to wrap your head around. Notice that the other way around is just as easy:\na[n] is converted to a[floor(n/m)][a%m]. Now for n dimensional arrays you might still argue that this only works if all the dimensions have the same size. But this is not the case. While our numbering system generally work with powers of some base. (e.g. 10^0, \u0026hellip; 10^n), this does not have to be and is not always the case. Just think of seconds, minutes, hours, days, months, years. To convert years into seconds, you have to multiply them by the size of every previous dimension. The same works for n dimensional arrays.\nWhy do 0-based indices work better here? Whether we are talking about number systems or flattened multidimensional arrays the underlying principle is that we have positions/digits which wrap around (modulo algebra) and carry over into the next position/digit. And modulo algebra is generally done from 0 to n-1 not from 1 to n. We generally don\u0026rsquo;t write 10:60 and instead wrap around from 10:59 to 11:00. Carrying over from minutes to hours. Similarly it is easier to wrap arrays after (n-1) and not n.\nA note on Column vs Row Major Storage I have used row major storage here. This means that we first go through the rows and then through the columns when enumerating our matrix.\nNow keen eyes might notice that we do not really specify what is a column or a row so you could just pretend it is different. But since we generally write column indices before row indices, we mean by \u0026ldquo;row major\u0026rdquo; that we first go through the right-most index. And that is fixed by the language.\nColumn major storage would also work, but that would mean we have to flip around a[ij] to a[j][i]. In a sense our numbering system is row major, the things close together are on the right, not the left. 55 is closer to 56 than to 65. And access behavior in programming languages obeys this principle. If you retrieve object.property.name from a hierarchical struct, then name is stored next to object.property.description. Not next to object.property2.name. Similarly an array of arrays (which is sometimes necessary if the sub arrays do not have the same size), will result in things closer together being on the right.\nLastly it is very easy to write down an array of arrays:\na = [ [1,2,3,4], [3,4,5,6] ]  which is easily and sensibly translated to a row major storage. You can also easily provide rows from a by writing a[i] and access a column from that row with a[i][j] which is the same element as a[ij]. While returning the column a[j] if you access a column major store would mean that the i-th row from that column a[j][i] corresponds to the element a[ij].\nSo column major storage violently collides with every other access convention.\nColumn major storage also means that\n$$x A^T$$\nfor a vector x and matrix A will be faster than\n$$ Ax $$\nThe fact that this convention is used in most scientific computing languages from Fortran, R and Matlab to now even Julia is disturbing.\n3. Divide and Conquer While you might still argue that n dimensional arrays can be abstracted away and do not matter, the fundamental principle which makes them work better with 0-based indices also makes \u0026ldquo;Divide and Conquer\u0026rdquo; algorithms easier with 0-based indices. Splitting n tasks into equally sized m portions is equivalent to equally distributing those n tasks over m rows in a matrix. In other words converting a one dimensional array of length n into an\n$$ m\\times\\text{ceil}(m/n)$$\narray. And divide and conquer algorithms are everywhere, from sorting algorithms to workload distribution over computing cores.\n4. Discretization Another task which is extremely common is the discretization of a continuous interval. One might for example want to discretize the interval from 0 to 1 with points distanced 1/n from each other: [0, 1/n,...,1]. The value at point i/n will correspond to the index i inside the value array. If you want to find the best approximation for a point between 0 and 1, you simply multiply it by n and round to the nearest integer \u0026ndash; that will be your index.\nI got asked once whether that was an artifact of the interval from 0 to 1. But that is again not the case. If we took the interval from 1 to 2, you would have to subtract 1 from your location when looking for the index in 0-based indexing sure, but you would also have to do that in 1-based indexing plus you would still have to fix the index in the end.\nTo get an intuition for why this is the case, consider n=10. Then our points are 0.0, 0.1, 0.2,..., 1.0 or 1.0, 1.1,...2.0, notice how the index is 0.i or 1.i respectively. Shifting the interval does not help because it shifts the wrong digit. And this also explains why counting from 0001 is weird. You start with every digit at 0 except for the 10^0 digit. So as soon as you shift the scale everything breaks, because you do not start counting from 1111 but from 0001. Counting from 0 is natural, we do it for every digit but the ones.\nNow you could shift the interval by your discretization size and start with 0.1, ..., 1.0. But then your interval/your starting point depends on the discretization. And generally any situation where you are discretizing, you very much care about 0 (e.g. time in physics simulations/differential equations).\nIt is also often the case that you want to compare two different discretizations to estimate whether or not you already have convergence. If you consider another discretization with points distanced 1/2n apart, then you can easily find the values of the rough discretizations by looking for the index a[i*2] in the array of finer discretizations.\n5. Ranges Lastly there is also the often cited argument by Dijkstra about ranges. As you might have noticed in the discretization argument, the number of points in [0.0,0.1,... 1.0] is not 10, it is 11. Similarly there are (n-m+1) elements in [m,...,n]. This +1 is quite confusing and irritating when slicing your data. So the idea is, that you want your ranges to include just as many elements as they are sized. To achieve that you need to drop either the first or the last element. In other words:\na[m:n] should either be [a[m+1],...,a[n]] or [a[m],...,a[n-1]].\nThe first variant is considered weird by most people (including proponents of 1-based indexing). The second variant does not work well with 1-based indices, as a[k:length(a)] would not include the last index. But this works extremely well for 0-based indexing precisely because the last element of an array of size n is the element at index n-1.\nBut Python does even more nifty things with ranges using zero based indexing. Instead of having to use something like a[length(a)-(k-1)] to obtain the k-th last element, you can simply wrap your array around and obtain a[-k]. In particular the last element is just a[-1].\nNow you could of course do the same with 1-based indices and make a[0] the last element, but I would personally find that extremely irritating \u0026ndash; modulo algebra is inherently 0-based.\nFinal Thoughts When I started to think about this issue I thought that you basically had to decide between ranges working intuitively, (lengths corresponding to differences) and the intuition that the i-th element should be at index i. Because one can not seem to have both.\nAnd at that point I would have already chosen ranges. Why? Because\n Slicing data into pieces is mentally much more challenging than retrieving a single index. So if one or the other should be made easier it should be the more difficult and thus more bug prone thing. I can not think of a single reason why you would want to access the i-th element in a programming language. You generally use arrays when all the elements have similar meaning and there is no reason to pick a particular element from the list. If they had special meaning using maps (dictionaries) or structs seems much more appropriate since you can give your entries names then. Slicing data on the other hand? You want to see the top 10 tourist attractions? Sure sort your dataframe and use df[:10]. Any divide and conquer algorithm is another example.  And since ranges are more challenging and used more often, I would have picked 0-based indexing based on this merit alone. But it is not the only reason one should make this decision. It is one of many.\nThe trap people fall into, is that they think of hand written lists when they think about indices. Sure, there it might be a bit more intuitive to use 1-based indices. But we are not handwriting lists here. We have to do much more complex things with indices, and 0-based indices just work much better when you actually have to do arithmetic with them.\nAnd sure you can abstract a lot of things away, but someone still has to write that code. And if you abstract it away then neither of them have any advantages. So we might as well use 0-based indexing at this point, since you should not see indices anyway. Lastly \u0026ldquo;use a library\u0026rdquo; should not be the answer to a design failure.\n","date":"2020-10-03","permalink":"https://www.unassuming.page/blog/programming/intuitive-indexing/","tags":["programming","maths"],"title":"Intuitive Indexing"},{"content":"It seems fitting that the first article of a blog should layout the foundation of my beliefs. So\u0026hellip;\nWhat is?  I think, therefore I am - Descartes\n We can be sure that something exists which does the thinking. You might now argue that abstract things like language and mathematics exist. Since a version of them can be part of your consciousness, which exists. But beyond that nothing concrete needs to exist, as thought experiments like Brain in a vat or Boltzmann Brains prove (as they are not falsifiable you can not prove you are not one of those, so therefore you can not prove that anything concrete must exist).\nWe thus know that this question is unsolvable beyond yourself and abstract concepts which exist within your thoughts.\nWhy? 1. Analogy/Intuition building A lot of triple-A games started to include minigames. This could be a card or board game in a tavern for example. Why is that interesting to us? Well consider playing a chess minigame. When you beat a piece – why do you do it?\nThe naïve answer is: “To win the game”. But then someone might ask: But why do you want to win the game? At which point you could go one level up and argue that, as the player character in the tavern, you want to win the bet placed on the game. Or improve your skills such that you can win such a bet in the future. A follow up might be: “Fair enough, but why do you want to earn money?”. You might of course argue that you can use it in order to buy a certain item, which will help you in your campaign. But then you could still ask: “Why do you want to beat the campaign of this game?”. You might go another level up and argue, that you want to beat this campaign in order to talk with your friends about it in real life.\nContinuing to ask “why?” long enough, will eventually lead you to a point where you would have to answer the meaning of life/the purpose of all your actions in your life. At which point some people go one level up and say: “To please my god and get into heaven”. But if we take a step back, we should start to realize: Going one level up is not really solving the problem, it is really just avoiding it.\n2. Abstract Reasoning Any answer to a “why?” question, could again be questioned. Such a chain of reasoning is either\n an infinite chain goes in circles or ends at some point  In order to build some intuition for this: Consider someone \u0026ldquo;walks\u0026rdquo; in order \u0026ldquo;to walk 1km\u0026rdquo;. We have an action with a purpose. We could now easily expand this chain by supporting the action of “walking” with the reason: “to walk 0.5km” and support the action of “walking 0.5km” with the goal of “walking 0.75km”, etc. And immediately we get an infinite chain of reasoning. And since neither the infinite chain of reasoning nor the circular reasoning is really satisfying, you might want to ask for a meta-reason for the entire chain/circle. In our example this could be \u0026ldquo;to walk 1km\u0026rdquo;.\nBut then we run into the same problem with chains of meta-reasons. In the end, we will not get to a truly satisfying answer. Now the naïve answer: “To win the game” suddenly sounds much better. If we already know we can get nowhere with our questions, maybe we should not start asking them to begin with.\n This might be a flavor of Absurdism. Although I have only skimmed the wikipedia article and watched a video so I am not quite sure.\n But if there is no meaning of life,\nWhat do? The absence of goals allows us to choose our own. And if we are allowed to do so, we might as well choose them according to our preferences. This will be slightly different for everyone.\nWhat is (second time)? As already argued, we cannot definitively answer this question. But since we now have to choose what we want to do as we reflected on our preferences, it might be helpful to have a model of the world around us so that we can predict the effects of our actions. Since that lets us evaluate them according to our preferences. Note that the evaluation of different actions changes with our model of the world, since it changes the predicted effect of our actions, which influences their evaluation according to our preferences.\n With very light assumptions on the preference relation (cf. Von Neumann-Morgenstern Utility Theorem) a utility function can be constructed. Once this utility function is obtained it is easy to see that we are in the setting of Reinforcement Learning (i.e. find the best policy/behaviour, which maximizes this utility function)\n No matter the preferences, it is beneficial if the model of the world has a lot of predictive power. Since that will result in valuations of actions closer to the “true” valuation, which would require perfect knowledge about how the world works. So how can we obtain a model with high predictive power?\nThis question seems similar to “What is?” on the surface. If we know what is, we can use this to predict what will be. The difference is that we can discard thought experiments like the Boltzmann Brain as not useful for predicting future events. Sure, it might be the case that you are such a Boltzmann Brain, but in that case, you will cease to exist in a few moments anyway and it does not matter what you do. And whether or not you are a brain in a vat in a simulated reality or “real” does not matter either, since we are not trying to definitively answer what truly is, but rather how our actions will influence what will be, and whether we like it. And then it does not matter whether the result is simulated or not.\nFor simplicity (and we will soon touch on how important simplicity is) it might be useful to assume, that your senses do tell you something about the real world. Now that we justified why we can rely on our senses again; we have essentially justified the Scientific Method (hypothesize, predict, test/observe, repeat). Making predictions from existing hypothesis is relatively straightforward, so is testing these predictions.\n Further testing by generating predictions which can be tested vs using a well-tested hypothesis (theory) for predictions which interest you (for choosing actions according to your preferences) is known and studied as the exploration vs. exploitation trade-off in Reinforcement Learning\n What is not straightforward is generating hypotheses from observations. “What are good hypotheses?” or “what can we learn?” are the questions which Statistical Learning is concerned with. Highlights include the No Free Lunch Theorem, which motivate the intuitive preference of scientists for simple/elegant hypothesis.\n We already argued that Mathematics exists so statistical learning\u0026rsquo;s theory can be relied on.\n While I recommend reading up on the “no free lunch theorem”, here is an intuitive explanation for the less mathematically inclined: If you do not assume, that physical laws are independent of space and time, they become exceedingly difficult to test. How can you confirm that some hypothesis is true, if the behaviour can change over time? It is quite hard to disprove a hypothesis which is allowed to change over time. Since that just means that it changed in such a way, that the results you got make sense again.\nThis problem is known as Overfitting and can intuitively understood with pictures like Figure 1 \u0026amp; 2.\n           Figure 1: by Chabacano - Own work, CC BY-SA 4.0, Link Figure 2: By Ghiles - Own work, CC BY-SA 4.0, Link    This simplicity requirement (which makes hypotheses robust), is the main problem with conspiracy theories. Sure they might explain the same observations, but they require a lot more “twists and turns” and are hard to test, since an observation which does not fit is simply incorporated with more twists and turns. This lack of falsifiability is the same reason, why God is a severe case of overfitting.\nThe number of twists and turns required to justify an omnipotent, benevolent god in a world with horrible disease is nauseating. And since it does not offer any measurable predictive power, the simpler hypothesis should be preferred.\nShould Where do morals come from in such a nihilistic worldview? Well for once most people prefer it, if a certain set of rules known as morals is adhered to. And since we do not justify preferences and simply view them as axioms, there is not really anything we need to add to that.\nBut understanding where they come from might help us build a better (simpler?) model of the world, which is desirable as already justified. Adding together the ingredients from Game Theory (evolutionary stable equilibriums and the Folk Theorem) and our scientific evidence that we are in fact a product of evolution, it is immediately apparent that an unspoken contract of not killing each other, etc. is in fact an Evolutionary Stable Nash Equilibrium in a repeated game. So the hypothesis that morals are in fact a Folk Theorem-esque Equilibria (which are enforced by the players) requires no additional assumptions and is as such extremely simple.\nIt is also a justification why people, which do not have these equilibria baked into their preferences/feelings (psychopaths), would still benefit from adhering to these Morals. Since Equilibria from Game Theory are also optimal for the individual.\nA word of caution While evolution is an optimization algorithm, any intermediate step is generally not optimal. And even in the limit, the result might only be a local optimum. It is often remarkably close to optimal - which is why the entire field of Bionics exists. But there is no guarantee that this is the case.\nSimilarly, assuming our intuitive Morals/Empathy have to be optimal (i.e. Evolutionary Stable Equilibriums) would likely be wrong. But at the same time, it is probably closer to optimal than we think. And Game Theory is only starting to understand the complex settings required to generate such behaviour. So it is likely a good rule of thumb to assume that our intuitive morals are probably rational in some way.\nTrolley Problem Let us consider the trolley problem for example, which is often used to test the edges of a Moral System. In order to avoid overcomplicated sentences, and since Folk-Theorem-esque Equilibriums are really (unwritten) social contracts. I will refer to this moral system as a social contract with the understanding that there need not be a written contract.\nA lot of attention is brought to the detail, that people are reluctant to switch the lever, and are especially reluctant to throw someone over the bridge railing in order to stop the trolley. This is no surprise once we realize that actively causing a death is a greater breach of the social contract, than not preventing a death. This is due to the reason that the contract enables people to feel safe around other people but does not make any guarantee about natural causes. You could never feel save around other people if they might, at any time, throw you under the bus for the greater good. The stress level of everyone would go through the roof. At the same time everyone can and should be more attentive when they move into dangerous places like train tracks. If you would ask people the question whether they prefer to live in a world, where they can feel safe around other people but are a bit more likely to get killed if they put themselves into dangerous places, compared to the other way around, most would pick the first option. Which is why this is the social contract which is enforced.\nThat said some edge cases do not really have to be decided if they virtually never happen. Since, if the probability of them happening is really low, they will have a negligible impact on the expected utility no matter the behaviour/actions in that situation.\nWho is covered? A lot of moral systems are problematic due to the fact, that they make a distinction between humans, animals and other things. But where are the borders? In the evolutionary progression from other apes where does a human start to become a human and attain coverage of the other set of morals? If the set of morals is simply a nash equilibrium/social contract, then the question whether someone is covered by it is simply a question whether someone is intelligent enough to agree to the terms and conditions of this contract. In other words: Animals are not protected, because they cannot provide us the same guarantees in return. They are not part of the social contract and thus also cannot break it, which is why they are only tried in courts by nutcases.\nCorollary: Artificial Intelligence should get these rights as soon as it can agree to this social contract.\nEmotions vs Rationality Since we do not require our preferences to be justified by some reason, our preferences and thus overarching goals will be greatly influenced by our emotions. But in order to avoid stumbling over your own feet, it is useful to evaluate actions rationality, or consider rationally whether they will interfere with your other preferences down the road. In that sense rationality is a tool for modelling the world in order to achieve more desirable outcomes.\n","date":"2020-10-03","permalink":"https://www.unassuming.page/blog/two-cents/philosophy-foundation/","tags":["two-cents","philosophy"],"title":"My Philosophical Foundation"}]