<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=HandheldFriendly content="True"><meta http-equiv=x-ua-compatible content="IE=edge"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=generator content="Hugo 0.75.1"><link rel="shortcut icon" href=https://cdn.jsdelivr.net/gh/dsrkafuu/dsr-cdn-main@1/images/favicons/dsrca.ico><title>Concise Philosophy - unAssuming</title><meta name=author content="Felix Benning"><meta name=description content="A Blog by Felix Benning"><meta name=keywords content="two-cents,philosophy"><meta property="og:title" content="Concise Philosophy"><meta name=twitter:title content="Concise Philosophy"><meta property="og:type" content="article"><meta property="og:url" content="https://www.unassuming.page/blog/two-cents/concise_philosophy/"><meta property="og:description" content="What is?

I think, therefore I am - Descartes

We can be sure that something exists which does the thinking. You might
now argue that abstract things like language and mathematics exist. Since a
version of them can be part of your consciousness, which exists. But beyond
that nothing concrete needs to exist, as thought experiments like Brain in a
vat or Boltzmann
Brains
prove (as they are not falsifiable you can not prove you are not one
of those, so therefore you can not prove that anything concrete must exist)."><meta name=twitter:description content="What is?

I think, therefore I am - Descartes

We can be sure that something exists which does the thinking. You might
now argue that abstract things like language and mathematics exist. Since a
version of them can be part of your consciousness, which exists. But beyond
that nothing concrete needs to exist, as thought experiments like Brain in a
vat or Boltzmann
Brains
prove (as they are not falsifiable you can not prove you are not one
of those, so therefore you can not prove that anything concrete must exist)."><meta name=twitter:card content="summary"><meta property="article:published_time" content="2020-10-03T00:00:00+00:00"><meta property="article:modified_time" content="2020-10-03T00:00:00+00:00"><style>@media(prefers-color-scheme:dark){body[data-theme=auto] img{filter:brightness(60%)}}body[data-theme=dark] img{filter:brightness(60%)}</style><link rel=stylesheet href=https://www.unassuming.page/assets/css/fuji.min.css></head><body data-theme=auto data-theme-auto=false><script data-cfasync=false>var fujiThemeData=localStorage.getItem('fuji_data-theme');if(!fujiThemeData){localStorage.setItem('fuji_data-theme','auto');}else{if(fujiThemeData!=='auto'){document.body.setAttribute('data-theme',fujiThemeData==='dark'?'dark':'light');}}</script><header><div class="container-lg clearfix"><div class="col-12 header"><a class=title-main href=https://www.unassuming.page>unAssuming</a></div></div></header><main><div class="container-lg clearfix"><div class="col-12 col-md-9 float-left content"><article><h2 class="post-item post-title"><a href=https://www.unassuming.page/blog/two-cents/concise_philosophy/>Concise Philosophy</a></h2><div class="post-item post-meta"><span><i class="iconfont icon-today-sharp"></i>&nbsp;2020-10-03</span>
<span><i class="iconfont icon-file-tray-sharp"></i>&nbsp;2205 words</span>
<span><i class="iconfont icon-pricetags-sharp"></i>&nbsp;<a href=/tags/two-cents>two-cents</a>&nbsp;<a href=/tags/philosophy>philosophy</a>&nbsp;</span></div><div class="post-content markdown-body"><h2 id=what-is>What is?</h2><blockquote><p>I think, therefore I am - <em>Descartes</em></p></blockquote><p>We can be sure that something exists which does the thinking. You might
now argue that abstract things like language and mathematics exist. Since a
version of them can be part of your consciousness, which exists. But beyond
that nothing concrete needs to exist, as thought experiments like <a href=https://en.wikipedia.org/wiki/Brain_in_a_vat target=_blank>Brain in a
vat</a> or <a href=https://en.wikipedia.org/wiki/Boltzmann_brain target=_blank>Boltzmann
Brains</a>
prove (as they are not falsifiable you can not prove you are <em>not</em> one
of those, so therefore you can not prove that anything concrete <em>must</em> exist).</p><p>We thus know that this question is unsolvable beyond yourself and abstract
concepts which exist within your thoughts.</p><h2 id=why>Why?</h2><h3 id=1-analogyintuition-building>1. Analogy/Intuition building</h3><p>A lot of triple-A games started to include minigames. This could be a card or
board game in a tavern for example. Why is that interesting to us? Well
consider playing a chess minigame. When you beat a piece – why do you do it?</p><p>The naïve answer is: “To win the game”. But then someone might ask: But why
do you want to win the game? At which point you could go one level up and
argue that, as the player character in the tavern, you want to win the bet
placed on the game. Or improve your skills such that you can win such a bet
in the future. A follow up might be: “Fair enough, but why do you want to
earn money?”. You might of course argue that you can use it in order to buy a
certain item, which will help you in your campaign. But then you could still
ask: “Why do you want to beat the campaign of this game?”. You might go
another level up and argue, that you want to beat this campaign in order to
talk with your friends about it in real life.</p><p>Continuing to ask “why?” long enough, will eventually lead you to a point
where you would have to answer the meaning of life/the purpose of all your
actions in your life. At which point some people go one level up and say: “To
please my god and get into heaven”. But if we take a step back, we should
start to realize: Going one level up is not really solving the problem,
it is really just avoiding it.</p><h3 id=2-abstract-reasoning>2. Abstract Reasoning</h3><p>Any answer to a “why?” question, could again be questioned. Such a chain of
reasoning is either</p><ul><li>an infinite chain</li><li>goes in circles or</li><li>ends at some point</li></ul><p>In order to build some intuition for this: Consider someone &ldquo;walks&rdquo; in
order &ldquo;to walk 1km&rdquo;. We have an action with a purpose. We could now easily
expand this chain by supporting the action of “walking” with the reason: “to
walk 0.5km” and support the action of “walking 0.5km” with the goal of
“walking 0.75km”, etc. And immediately we get an infinite chain of reasoning.
And since neither the infinite chain of reasoning nor the circular reasoning
is really satisfying, you might want to ask for a meta-reason for the entire
chain/circle. In our example this could be &ldquo;to walk 1km&rdquo;.</p><p>But then we run into the same problem with chains of meta-reasons. In the
end, we will not get to a truly satisfying answer. Now the naïve answer: “To
win the game” suddenly sounds much better. If we already know we can get
nowhere with our questions, maybe we should not start asking them to begin
with.</p><p>But if there is no meaning of life,</p><h2 id=what-do>What do?</h2><p>The absence of goals allows us to choose our own. And if we are allowed to do
so, we might as well choose them according to our <em>preferences</em>. This will be
slightly different for everyone.</p><h2 id=what-is-second-time>What is (second time)?</h2><p>As already argued, we cannot definitively answer this question. But since we
now have to choose what we want to do as we reflected on our preferences, it
might be helpful to have a model of the world around us so that we can
predict the effects of our actions. Since that lets us evaluate them
according to our preferences. Note that the evaluation of different actions
changes with our model of the world, since it changes the predicted effect of
our actions, which influences their evaluation according to our preferences.</p><blockquote><p>With very light assumptions on the preference relation (cf. <a href=https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem target=_blank>Von
Neumann-Morgenstern Utility
Theorem</a>)
a utility function can be constructed.
Once this utility function is obtained it is easy to see that we are in the
setting of Reinforcement Learning (i.e. find the best policy/behaviour, which
maximizes this utility function)</p></blockquote><p>No matter the preferences, it is beneficial if the model of the world has a
lot of predictive power. Since that will result in valuations of actions
closer to the “true” valuation, which would require perfect knowledge about
how the world works. So how can we obtain a model with high predictive power?</p><p>This question seems similar to “What is?” on the surface. If we know what is,
we can use this to predict what will be. The difference is that we can
discard thought experiments like the Boltzmann Brain as not useful for
predicting future events. Sure, it might be the case that you are such a
Boltzmann Brain, but in that case, you will cease to exist in a few moments
anyway and it does not matter what you do. And whether or not you are a brain
in a vat in a simulated reality or “real” does not matter either, since we
are not trying to definitively answer what truly is, but rather how our
actions will influence what will be, and whether we like it. And then it does
not matter whether the result is simulated or not.</p><p>For simplicity (and we will soon touch on how important simplicity is) it
might be useful to assume, that your senses do tell you something about
the real world. Now that we justified why we can rely on our senses again; we
have essentially justified the <a href=https://en.wikipedia.org/wiki/Scientific_method target=_blank>Scientific
Method</a> (hypothesize,
predict, test/observe, repeat). Making predictions from existing hypothesis is
relatively straightforward, so is testing these predictions.</p><blockquote><p>Further testing by generating predictions which can be tested vs using a
well-tested hypothesis (theory) for predictions which interest you (for
choosing actions according to your preferences) is known and studied as the
exploration vs. exploitation trade-off in Reinforcement Learning</p></blockquote><p>What is not straightforward is generating hypotheses from observations. “What
are good hypotheses?” or “what can we learn?” are the questions which
<a href=https://en.wikipedia.org/wiki/Statistical_learning_theory target=_blank>Statistical
Learning</a> is
concerned with. Highlights include the <a href=https://en.wikipedia.org/wiki/No_free_lunch_theorem target=_blank>No Free Lunch
Theorem</a>, which motivate
the intuitive preference of scientists for simple/elegant hypothesis.</p><blockquote><p>We already argued that Mathematics <a href=#what-is>exists</a> so statistical
learning&rsquo;s theory can be relied on.</p></blockquote><p>While I
recommend reading up on the “no free lunch theorem”, here is an intuitive
explanation for the less mathematically inclined: If you do not assume, that
physical laws are independent of space and time, they become exceedingly
difficult to test. How can you confirm that some hypothesis is true, if the
behaviour can change over time? It is quite hard to disprove a hypothesis
which is allowed to change over time. Since that just means that it changed
in such a way, that the results you got make sense again.</p><p>This problem is known as
<a href=https://en.wikipedia.org/wiki/Overfitting target=_blank>Overfitting</a> and can intuitively
understood with pictures like Figure 1 & 2.</p><table><thead><tr><th><p><img src=/images/concise_philosophy/fig1.svg alt="Figure 1"></p></th><th><p><img src=/images/concise_philosophy/fig2.png alt="Figure 2"></p></th></tr></thead><tbody><tr><td>Figure 1: by <a href=//commons.wikimedia.org/wiki/User:Chabacano class=mw-redirect title=User:Chabacano>Chabacano</a> - <span class=int-own-work lang=en>Own work</span>, <a href=https://creativecommons.org/licenses/by-sa/4.0 title="Creative Commons Attribution-Share Alike 4.0">CC BY-SA 4.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=3610704">Link</a></td><td>Figure 2: By <a href="//commons.wikimedia.org/w/index.php?title=User:Ghiles&action=edit&redlink=1" class=new title="User:Ghiles (page does not exist)">Ghiles</a> - <span class=int-own-work lang=en>Own work</span>, <a href=https://creativecommons.org/licenses/by-sa/4.0 title="Creative Commons Attribution-Share Alike 4.0">CC BY-SA 4.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=47471056">Link</a></td></tr></tbody></table><p>This simplicity requirement (which makes hypotheses robust), is the main
problem with conspiracy theories. Sure they might explain the same
observations, but they require a lot more “twists and turns” and are hard to
test, since an observation which does not fit is simply incorporated with
more twists and turns. This lack of falsifiability is the same reason, why
God is a severe case of overfitting.</p><p>The number of twists and turns required
to justify an omnipotent, benevolent god in a world with horrible disease is
nauseating. And since it does not offer any measurable predictive power, the
simpler hypothesis should be preferred.</p><h2 id=should>Should</h2><p>Where do morals come from in such a nihilistic worldview? Well for once most
people prefer it, if a certain set of rules known as morals is adhered to.
And since we do not justify preferences and simply view them as axioms,
there is not really anything we need to add to that.</p><p>But understanding where they come from might help us build a better
(simpler?) model of the world, which is desirable as already justified.
Adding together the ingredients from Game Theory (evolutionary stable
equilibriums and the Folk Theorem) and our scientific evidence that we are in
fact a product of evolution, it is immediately apparent that an unspoken
contract of not killing each other, etc. is in fact an Evolutionary Stable
Nash Equilibrium in a repeated game. So the hypothesis that morals are in
fact a Folk Theorem-esque Equilibria (which are enforced by the players)
requires no additional assumptions and is as such extremely simple.</p><p>It is also a justification why people, which do not have these equilibria
baked into their preferences/feelings (psychopaths), would still benefit from
adhering to these Morals. Since Equilibria from Game Theory are also
optimal for the individual.</p><h3 id=a-word-of-caution>A word of caution</h3><p>While evolution is an optimization algorithm, any intermediate step is
generally not optimal. And even in the limit, the result might only be a
local optimum. It is often remarkably close to optimal - which is why the
entire field of <a href=https://en.wikipedia.org/wiki/Bionics target=_blank>Bionics</a> exists. But
there is no guarantee that this is the case.</p><p>Similarly, assuming our intuitive Morals/Empathy have to be optimal (i.e.
Evolutionary Stable Equilibriums) would likely be wrong. But at the same
time, it is probably closer to optimal than we think. And Game Theory is only
starting to understand the complex settings required to generate such
behaviour. So it is likely a good rule of thumb to assume that our intuitive
morals are probably rational in some way.</p><h3 id=trolley-problem>Trolley Problem</h3><p>Let us consider the trolley problem for example, which is often used to test
the edges of a Moral System. In order to avoid overcomplicated sentences, and
since Folk-Theorem-esque Equilibriums are really (unwritten) social
contracts. I will refer to this moral system as a social contract with the
understanding that there need not be a written contract.</p><p>A lot of attention is brought to the detail, that people are reluctant to
switch the lever, and are especially reluctant to throw someone over the
bridge railing in order to stop the trolley. This is no surprise once we
realize that actively causing a death is a greater breach of the social
contract, than not preventing a death. This is due to the reason that the
contract enables people to feel safe around other people but does not make
any guarantee about natural causes. You could never feel save around other
people if they might, at any time, throw you under the bus for the greater
good. The stress level of everyone would go through the roof. At the same
time everyone can and should be more attentive when they move into dangerous
places like train tracks. If you would ask people the question whether they
prefer to live in a world, where they can feel safe around other people but
are a bit more likely to get killed if they put themselves into dangerous
places, compared to the other way around, most would pick the first option.
Which is why this is the social contract which is enforced.</p><p>That said some edge cases do not really have to be decided if they virtually
never happen. Since, if the probability of them happening is really low,
they will have a negligible impact on the expected utility no matter the
behaviour/actions in that situation.</p><h3 id=who-is-covered>Who is covered?</h3><p>A lot of moral systems are problematic due to the fact, that they make a
distinction between humans, animals and other things. But where are the
borders? In the evolutionary progression from other apes where does a human
start to become a human and attain coverage of the other set of morals? If
the set of morals is simply a nash equilibrium/social contract, then the
question whether someone is covered by it is simply a question whether
someone is intelligent enough to agree to the terms and conditions of this
contract. In other words: Animals are not protected, because they cannot
provide us the same guarantees in return. They are not part of the social
contract and thus also cannot break it, which is why they are only tried in
courts by nutcases.</p><p>Corollary: Artificial Intelligence should get these rights as soon as it can
agree to this social contract.</p><h3 id=emotions-vs-rationality>Emotions vs Rationality</h3><p>Since we do not require our preferences to be justified by some reason, our
preferences and thus overarching goals will be greatly influenced by our
emotions. But in order to avoid stumbling over your own feet, it is useful to
evaluate actions rationality, or consider rationally whether they will
interfere with your other preferences down the road. In that sense
rationality is a tool for modelling the world in order to achieve more
desirable outcomes.</p></div></article><div class=post-comment data-comment=utterances><span class=post-comment-notloaded><i class="iconfont icon-chatbox-ellipses-sharp"></i>&nbsp;Load comments</span>
<script>function loadComment(){var commentArea=document.querySelector('.post-comment');var utterancesTheme=document.body.getAttribute('data-theme');if(utterancesTheme==='auto'){utterancesTheme=window.matchMedia('(prefers-color-scheme: dark)').matches?'photon-dark':'github-light';}else{utterancesTheme=utterancesTheme==='dark'?'photon-dark':'github-light';}
var s=document.createElement('script');s.src='https://utteranc.es/client.js';s.setAttribute('repo','FelixBenning\/FelixBenning.github.io');s.setAttribute('issue-term','pathname');s.setAttribute('theme',utterancesTheme);s.setAttribute('crossorigin','anonymous');s.setAttribute('async','');document.querySelector('.post-comment').appendChild(s);document.querySelector('span.post-comment-notloaded').setAttribute('style','display: none;');}</script></div></div><aside class="col-12 col-md-3 float-left sidebar"><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul><li><a href=/archives/>Archives</a></li><li><a href=/about/>About</a></li><li><a href=/search/>Search</a></li></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul><li><a href=https://github.com/FelixBenning target=_blank><span>GitHub</span></a></li><li><a href=mailto:Felix.Benning@gmail.com target=_blank><span>Email</span></a></li></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div><span><a href=/tags/algebra/>algebra</a></span>
<span><a href=/tags/analysis/>analysis</a></span>
<span><a href=/tags/climate-change/>climate-change</a></span>
<span><a href=/tags/economics/>economics</a></span>
<span><a href=/tags/education/>education</a></span>
<span><a href=/tags/health/>health</a></span>
<span><a href=/tags/linear-algebra/>linear-algebra</a></span>
<span><a href=/tags/maths/>maths</a></span>
<span><a href=/tags/philosophy/>philosophy</a></span>
<span><a href=/tags/politics/>politics</a></span>
<span><a href=/tags/programming/>programming</a></span>
<span><a href=/tags/tools/>tools</a></span>
<span><a href=/tags/two-cents/>two-cents</a></span></div></div><div class="sidebar-item sidebar-toc"><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#what-is>What is?</a></li><li><a href=#why>Why?</a><ul><li><a href=#1-analogyintuition-building>1. Analogy/Intuition building</a></li><li><a href=#2-abstract-reasoning>2. Abstract Reasoning</a></li></ul></li><li><a href=#what-do>What do?</a></li><li><a href=#what-is-second-time>What is (second time)?</a></li><li><a href=#should>Should</a><ul><li><a href=#a-word-of-caution>A word of caution</a></li><li><a href=#trolley-problem>Trolley Problem</a></li><li><a href=#who-is-covered>Who is covered?</a></li><li><a href=#emotions-vs-rationality>Emotions vs Rationality</a></li></ul></li></ul></nav></div></aside></div><div class=btn><div class=btn-menu id=btn-menu><i class="iconfont icon-grid-sharp"></i></div><div class=btn-toggle-mode><i class="iconfont icon-contrast-sharp"></i></div><div class=btn-scroll-top><i class="iconfont icon-chevron-up-circle-sharp"></i></div></div><aside class=sidebar-mobile style=display:none><div class=sidebar-wrapper><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul><li><a href=/archives/>Archives</a></li><li><a href=/about/>About</a></li><li><a href=/search/>Search</a></li></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul><li><a href=https://github.com/FelixBenning target=_blank><span>GitHub</span></a></li><li><a href=mailto:Felix.Benning@gmail.com target=_blank><span>Email</span></a></li></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div><span><a href=/tags/algebra/>algebra</a></span>
<span><a href=/tags/analysis/>analysis</a></span>
<span><a href=/tags/climate-change/>climate-change</a></span>
<span><a href=/tags/economics/>economics</a></span>
<span><a href=/tags/education/>education</a></span>
<span><a href=/tags/health/>health</a></span>
<span><a href=/tags/linear-algebra/>linear-algebra</a></span>
<span><a href=/tags/maths/>maths</a></span>
<span><a href=/tags/philosophy/>philosophy</a></span>
<span><a href=/tags/politics/>politics</a></span>
<span><a href=/tags/programming/>programming</a></span>
<span><a href=/tags/tools/>tools</a></span>
<span><a href=/tags/two-cents/>two-cents</a></span></div></div><div class="sidebar-item sidebar-toc"><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#what-is>What is?</a></li><li><a href=#why>Why?</a><ul><li><a href=#1-analogyintuition-building>1. Analogy/Intuition building</a></li><li><a href=#2-abstract-reasoning>2. Abstract Reasoning</a></li></ul></li><li><a href=#what-do>What do?</a></li><li><a href=#what-is-second-time>What is (second time)?</a></li><li><a href=#should>Should</a><ul><li><a href=#a-word-of-caution>A word of caution</a></li><li><a href=#trolley-problem>Trolley Problem</a></li><li><a href=#who-is-covered>Who is covered?</a></li><li><a href=#emotions-vs-rationality>Emotions vs Rationality</a></li></ul></li></ul></nav></div></div></aside></main><footer><div class="container-lg clearfix"><div class="col-12 footer"><span>&copy; 2022
<a href=https://www.unassuming.page>Felix Benning</a>
| Powered by <a href=https://github.com/dsrkafuu/hugo-theme-fuji/ target=_blank>Fuji-v2</a> & <a href=https://gohugo.io/ target=_blank>Hugo</a></span></div></div></footer><script defer src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/components/prism-core.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/plugins/autoloader/prism-autoloader.min.js></script><script defer src=/assets/js/fuji.min.js></script></body></html>